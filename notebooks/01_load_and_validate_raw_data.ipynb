{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yellow_tripdata_2021-01.parquet already exists. Skipping download.\n",
      "green_tripdata_2021-01.parquet already exists. Skipping download.\n",
      "fhv_tripdata_2021-01.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-01.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-02.parquet already exists. Skipping download.\n",
      "green_tripdata_2021-02.parquet already exists. Skipping download.\n",
      "fhv_tripdata_2021-02.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-02.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-03.parquet already exists. Skipping download.\n",
      "green_tripdata_2021-03.parquet already exists. Skipping download.\n",
      "fhv_tripdata_2021-03.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-03.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-04.parquet already exists. Skipping download.\n",
      "green_tripdata_2021-04.parquet already exists. Skipping download.\n",
      "fhv_tripdata_2021-04.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-04.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-05.parquet already exists. Skipping download.\n",
      "green_tripdata_2021-05.parquet already exists. Skipping download.\n",
      "fhv_tripdata_2021-05.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-05.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-06.parquet already exists. Skipping download.\n",
      "green_tripdata_2021-06.parquet already exists. Skipping download.\n",
      "fhv_tripdata_2021-06.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-06.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-07.parquet already exists. Skipping download.\n",
      "green_tripdata_2021-07.parquet already exists. Skipping download.\n",
      "fhv_tripdata_2021-07.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-07.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-08.parquet already exists. Skipping download.\n",
      "green_tripdata_2021-08.parquet already exists. Skipping download.\n",
      "fhv_tripdata_2021-08.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-08.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-09.parquet already exists. Skipping download.\n",
      "green_tripdata_2021-09.parquet already exists. Skipping download.\n",
      "fhv_tripdata_2021-09.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-09.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-10.parquet already exists. Skipping download.\n",
      "green_tripdata_2021-10.parquet already exists. Skipping download.\n",
      "fhv_tripdata_2021-10.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-10.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-11.parquet already exists. Skipping download.\n",
      "green_tripdata_2021-11.parquet already exists. Skipping download.\n",
      "fhv_tripdata_2021-11.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-11.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-12.parquet already exists. Skipping download.\n",
      "green_tripdata_2021-12.parquet already exists. Skipping download.\n",
      "fhv_tripdata_2021-12.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-12.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2022-01.parquet already exists. Skipping download.\n",
      "green_tripdata_2022-01.parquet already exists. Skipping download.\n",
      "fhv_tripdata_2022-01.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2022-01.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2022-02.parquet already exists. Skipping download.\n",
      "green_tripdata_2022-02.parquet already exists. Skipping download.\n",
      "fhv_tripdata_2022-02.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2022-02.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2022-03.parquet already exists. Skipping download.\n",
      "green_tripdata_2022-03.parquet already exists. Skipping download.\n",
      "fhv_tripdata_2022-03.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2022-03.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2022-04.parquet already exists. Skipping download.\n",
      "green_tripdata_2022-04.parquet already exists. Skipping download.\n",
      "fhv_tripdata_2022-04.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2022-04.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2022-05.parquet already exists. Skipping download.\n",
      "green_tripdata_2022-05.parquet already exists. Skipping download.\n",
      "fhv_tripdata_2022-05.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2022-05.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2022-06.parquet already exists. Skipping download.\n",
      "green_tripdata_2022-06.parquet already exists. Skipping download.\n",
      "fhv_tripdata_2022-06.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2022-06.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2022-07.parquet already exists. Skipping download.\n",
      "green_tripdata_2022-07.parquet already exists. Skipping download.\n",
      "fhv_tripdata_2022-07.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2022-07.parquet downloaded successfully to ../data/raw\n",
      "yellow_tripdata_2022-08.parquet already exists. Skipping download.\n",
      "green_tripdata_2022-08.parquet downloaded successfully to ../data/raw\n",
      "fhv_tripdata_2022-08.parquet downloaded successfully to ../data/raw\n"
     ]
    }
   ],
   "source": [
    "# fetch the file from the server\n",
    "\n",
    "import requests\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def fetch_raw_data(url, file_name, repo_dir='../data/raw'):\n",
    "    \"\"\"\n",
    "    Downloads the file from the provided URL if it doesn't already exist in the directory.\n",
    "    \n",
    "    Args:\n",
    "    - url: The URL from which the file will be downloaded.\n",
    "    - file_name: The name with which the file will be saved.\n",
    "    - repo_dir: The directory where the file will be saved (default: '../data/raw').\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    file_path = Path(repo_dir) / file_name\n",
    "\n",
    "    # Check if the file already exists\n",
    "    if file_path.exists():\n",
    "        print(f'{file_name} already exists. Skipping download.')\n",
    "        return\n",
    "\n",
    "    # Attempt to download the file\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the download was successful\n",
    "    if response.status_code == 200:\n",
    "        Path(repo_dir).mkdir(parents=True, exist_ok=True)\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f'{file_name} downloaded successfully to {repo_dir}')\n",
    "    else:\n",
    "        raise Exception(f'Status code error: {response.status_code} - File not available!')\n",
    "\n",
    "\n",
    "def download_yellow_monthly_data(year, month):\n",
    "    url = f'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{year}-{month}.parquet'\n",
    "    file_name = f'yellow_tripdata_{year}-{month}.parquet'\n",
    "    fetch_raw_data(url, file_name)\n",
    "\n",
    "def download_green_monthly_data(year, month):\n",
    "    url = f'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_{year}-{month}.parquet'\n",
    "    file_name = f'green_tripdata_{year}-{month}.parquet'\n",
    "    fetch_raw_data(url, file_name)\n",
    "\n",
    "def download_fhv_monthly_data(year, month):\n",
    "    url = f'https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_{year}-{month}.parquet'\n",
    "    file_name = f'fhv_tripdata_{year}-{month}.parquet'\n",
    "    fetch_raw_data(url, file_name)\n",
    "\n",
    "def download_fhvhv_monthly_data(year, month):\n",
    "    url = f'https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_{year}-{month}.parquet'\n",
    "    file_name = f'fhvhv_tripdata_{year}-{month}.parquet'\n",
    "    fetch_raw_data(url, file_name)\n",
    "\n",
    "def nyc_data_extrator(year, month):\n",
    "    download_yellow_monthly_data(year, month)\n",
    "    download_green_monthly_data(year, month)\n",
    "    download_fhv_monthly_data(year, month)\n",
    "    download_fhvhv_monthly_data(year, month)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    years = ['2021', '2022', '2023']\n",
    "    months = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "\n",
    "    for year in years:\n",
    "        for month in months:\n",
    "            nyc_data_extrator(year, month)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao fazer a requisição: 403\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "import requests\n",
    "\n",
    "year = '2022'\n",
    "month = '01'\n",
    "# URL do endpoint da API\n",
    "url = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{year}-{month}.parquet'\n",
    "\n",
    "# Adicionar o cabeçalho User-Agent\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "\n",
    "# Fazer a requisição GET à API com o cabeçalho\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Verificar se a requisição foi bem-sucedida\n",
    "if response.status_code == 200:\n",
    "    # Carregar o conteúdo da resposta em um BytesIO\n",
    "    data = BytesIO(response.content)\n",
    "    \n",
    "    # Ler o conteúdo usando pandas.read_parquet\n",
    "    df = pd.read_parquet(data)\n",
    "\n",
    "    # Exibir o dataframe\n",
    "    print('foi')\n",
    "\n",
    "else:\n",
    "    print(f'Erro ao fazer a requisição: {response.status_code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag', 'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount', 'congestion_surcharge'\n",
    "    ]\n",
    "\n",
    "important_columns = ['tpep_pickup_datetime', 'PULocationID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "params = {'year': '2021', 'month': '01'}\n",
    "\n",
    "df = pd.read_parquet('../data/raw/yellow_tripdata_{year}-{month}.parquet'.format(**params), columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green = pd.read_parquet('../data/raw/green_tripdata_{year}-{month}.parquet'.format(**params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:15:56</td>\n",
       "      <td>2021-01-01 00:19:52</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43</td>\n",
       "      <td>151</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.01</td>\n",
       "      <td>5.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.80</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:25:59</td>\n",
       "      <td>2021-01-01 00:34:44</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>166</td>\n",
       "      <td>239</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.53</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:45:57</td>\n",
       "      <td>2021-01-01 00:51:55</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-12-31 23:57:51</td>\n",
       "      <td>2021-01-01 00:04:56</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>168</td>\n",
       "      <td>75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.99</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:16:36</td>\n",
       "      <td>2021-01-01 00:16:40</td>\n",
       "      <td>N</td>\n",
       "      <td>2.0</td>\n",
       "      <td>265</td>\n",
       "      <td>265</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-52.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-52.80</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76513</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-31 21:38:00</td>\n",
       "      <td>2021-01-31 22:16:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.63</td>\n",
       "      <td>56.23</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.12</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>65.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76514</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-31 22:43:00</td>\n",
       "      <td>2021-01-31 23:21:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.36</td>\n",
       "      <td>46.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.20</td>\n",
       "      <td>6.12</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>65.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76515</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-31 22:16:00</td>\n",
       "      <td>2021-01-31 22:27:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.50</td>\n",
       "      <td>18.95</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>22.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76516</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-31 23:10:00</td>\n",
       "      <td>2021-01-31 23:37:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>168</td>\n",
       "      <td>215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.48</td>\n",
       "      <td>48.87</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.12</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>58.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76517</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-31 23:25:00</td>\n",
       "      <td>2021-01-31 23:35:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119</td>\n",
       "      <td>244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.81</td>\n",
       "      <td>15.45</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>18.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76518 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
       "0             2  2021-01-01 00:15:56   2021-01-01 00:19:52                  N   \n",
       "1             2  2021-01-01 00:25:59   2021-01-01 00:34:44                  N   \n",
       "2             2  2021-01-01 00:45:57   2021-01-01 00:51:55                  N   \n",
       "3             2  2020-12-31 23:57:51   2021-01-01 00:04:56                  N   \n",
       "4             2  2021-01-01 00:16:36   2021-01-01 00:16:40                  N   \n",
       "...         ...                  ...                   ...                ...   \n",
       "76513         2  2021-01-31 21:38:00   2021-01-31 22:16:00               None   \n",
       "76514         2  2021-01-31 22:43:00   2021-01-31 23:21:00               None   \n",
       "76515         2  2021-01-31 22:16:00   2021-01-31 22:27:00               None   \n",
       "76516         2  2021-01-31 23:10:00   2021-01-31 23:37:00               None   \n",
       "76517         2  2021-01-31 23:25:00   2021-01-31 23:35:00               None   \n",
       "\n",
       "       RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
       "0             1.0            43           151              1.0           1.01   \n",
       "1             1.0           166           239              1.0           2.53   \n",
       "2             1.0            41            42              1.0           1.12   \n",
       "3             1.0           168            75              1.0           1.99   \n",
       "4             2.0           265           265              3.0           0.00   \n",
       "...           ...           ...           ...              ...            ...   \n",
       "76513         NaN            81            90              NaN          17.63   \n",
       "76514         NaN            35           213              NaN          18.36   \n",
       "76515         NaN            74            69              NaN           2.50   \n",
       "76516         NaN           168           215              NaN          14.48   \n",
       "76517         NaN           119           244              NaN           1.81   \n",
       "\n",
       "       fare_amount  extra  mta_tax  tip_amount  tolls_amount ehail_fee  \\\n",
       "0             5.50   0.50      0.5        0.00          0.00      None   \n",
       "1            10.00   0.50      0.5        2.81          0.00      None   \n",
       "2             6.00   0.50      0.5        1.00          0.00      None   \n",
       "3             8.00   0.50      0.5        0.00          0.00      None   \n",
       "4           -52.00   0.00     -0.5        0.00          0.00      None   \n",
       "...            ...    ...      ...         ...           ...       ...   \n",
       "76513        56.23   2.75      0.0        0.00          6.12      None   \n",
       "76514        46.66   0.00      0.0       12.20          6.12      None   \n",
       "76515        18.95   2.75      0.0        0.00          0.00      None   \n",
       "76516        48.87   2.75      0.0        0.00          6.12      None   \n",
       "76517        15.45   2.75      0.0        0.00          0.00      None   \n",
       "\n",
       "       improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
       "0                        0.3          6.80           2.0        1.0   \n",
       "1                        0.3         16.86           1.0        1.0   \n",
       "2                        0.3          8.30           1.0        1.0   \n",
       "3                        0.3          9.30           2.0        1.0   \n",
       "4                       -0.3        -52.80           3.0        1.0   \n",
       "...                      ...           ...           ...        ...   \n",
       "76513                    0.3         65.40           NaN        NaN   \n",
       "76514                    0.3         65.28           NaN        NaN   \n",
       "76515                    0.3         22.00           NaN        NaN   \n",
       "76516                    0.3         58.04           NaN        NaN   \n",
       "76517                    0.3         18.50           NaN        NaN   \n",
       "\n",
       "       congestion_surcharge  \n",
       "0                      0.00  \n",
       "1                      2.75  \n",
       "2                      0.00  \n",
       "3                      0.00  \n",
       "4                      0.00  \n",
       "...                     ...  \n",
       "76513                   NaN  \n",
       "76514                   NaN  \n",
       "76515                   NaN  \n",
       "76516                   NaN  \n",
       "76517                   NaN  \n",
       "\n",
       "[76518 rows x 20 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fhv = pd.read_parquet('../data/raw/fhv_tripdata_{year}-{month}.parquet'.format(**params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropOff_datetime</th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2021-01-01 00:27:00</td>\n",
       "      <td>2021-01-01 00:44:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2021-01-01 00:50:00</td>\n",
       "      <td>2021-01-01 01:07:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00013</td>\n",
       "      <td>2021-01-01 00:01:00</td>\n",
       "      <td>2021-01-01 01:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B00013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-01-01 00:13:09</td>\n",
       "      <td>2021-01-01 00:21:26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-01-01 00:38:31</td>\n",
       "      <td>2021-01-01 00:53:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154107</th>\n",
       "      <td>B03266</td>\n",
       "      <td>2021-01-31 23:43:03</td>\n",
       "      <td>2021-01-31 23:51:48</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B03266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154108</th>\n",
       "      <td>B03284</td>\n",
       "      <td>2021-01-31 23:50:27</td>\n",
       "      <td>2021-02-01 00:48:03</td>\n",
       "      <td>44.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154109</th>\n",
       "      <td>B03285</td>\n",
       "      <td>2021-01-31 23:13:46</td>\n",
       "      <td>2021-01-31 23:29:58</td>\n",
       "      <td>171.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B03285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154110</th>\n",
       "      <td>B03285</td>\n",
       "      <td>2021-01-31 23:58:03</td>\n",
       "      <td>2021-02-01 00:17:29</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B03285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154111</th>\n",
       "      <td>B03321</td>\n",
       "      <td>2021-01-31 23:39:00</td>\n",
       "      <td>2021-02-01 00:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B03321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1154112 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        dispatching_base_num     pickup_datetime    dropOff_datetime  \\\n",
       "0                     B00009 2021-01-01 00:27:00 2021-01-01 00:44:00   \n",
       "1                     B00009 2021-01-01 00:50:00 2021-01-01 01:07:00   \n",
       "2                     B00013 2021-01-01 00:01:00 2021-01-01 01:51:00   \n",
       "3                     B00037 2021-01-01 00:13:09 2021-01-01 00:21:26   \n",
       "4                     B00037 2021-01-01 00:38:31 2021-01-01 00:53:44   \n",
       "...                      ...                 ...                 ...   \n",
       "1154107               B03266 2021-01-31 23:43:03 2021-01-31 23:51:48   \n",
       "1154108               B03284 2021-01-31 23:50:27 2021-02-01 00:48:03   \n",
       "1154109      B03285          2021-01-31 23:13:46 2021-01-31 23:29:58   \n",
       "1154110      B03285          2021-01-31 23:58:03 2021-02-01 00:17:29   \n",
       "1154111               B03321 2021-01-31 23:39:00 2021-02-01 00:15:00   \n",
       "\n",
       "         PUlocationID  DOlocationID SR_Flag Affiliated_base_number  \n",
       "0                 NaN           NaN    None                 B00009  \n",
       "1                 NaN           NaN    None                 B00009  \n",
       "2                 NaN           NaN    None                 B00013  \n",
       "3                 NaN          72.0    None                 B00037  \n",
       "4                 NaN          61.0    None                 B00037  \n",
       "...               ...           ...     ...                    ...  \n",
       "1154107           7.0           7.0    None                 B03266  \n",
       "1154108          44.0          91.0    None                         \n",
       "1154109         171.0         171.0    None        B03285           \n",
       "1154110          15.0          15.0    None        B03285           \n",
       "1154111           NaN           NaN    None                 B03321  \n",
       "\n",
       "[1154112 rows x 7 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fhv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fhv = pd.read_parquet('../data/raw/fhv_tripdata_{year}-{month}.parquet'.format(**params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropOff_datetime</th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2021-01-01 00:27:00</td>\n",
       "      <td>2021-01-01 00:44:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2021-01-01 00:50:00</td>\n",
       "      <td>2021-01-01 01:07:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00013</td>\n",
       "      <td>2021-01-01 00:01:00</td>\n",
       "      <td>2021-01-01 01:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B00013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-01-01 00:13:09</td>\n",
       "      <td>2021-01-01 00:21:26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-01-01 00:38:31</td>\n",
       "      <td>2021-01-01 00:53:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154107</th>\n",
       "      <td>B03266</td>\n",
       "      <td>2021-01-31 23:43:03</td>\n",
       "      <td>2021-01-31 23:51:48</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B03266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154108</th>\n",
       "      <td>B03284</td>\n",
       "      <td>2021-01-31 23:50:27</td>\n",
       "      <td>2021-02-01 00:48:03</td>\n",
       "      <td>44.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154109</th>\n",
       "      <td>B03285</td>\n",
       "      <td>2021-01-31 23:13:46</td>\n",
       "      <td>2021-01-31 23:29:58</td>\n",
       "      <td>171.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B03285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154110</th>\n",
       "      <td>B03285</td>\n",
       "      <td>2021-01-31 23:58:03</td>\n",
       "      <td>2021-02-01 00:17:29</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B03285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154111</th>\n",
       "      <td>B03321</td>\n",
       "      <td>2021-01-31 23:39:00</td>\n",
       "      <td>2021-02-01 00:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B03321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1154112 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        dispatching_base_num     pickup_datetime    dropOff_datetime  \\\n",
       "0                     B00009 2021-01-01 00:27:00 2021-01-01 00:44:00   \n",
       "1                     B00009 2021-01-01 00:50:00 2021-01-01 01:07:00   \n",
       "2                     B00013 2021-01-01 00:01:00 2021-01-01 01:51:00   \n",
       "3                     B00037 2021-01-01 00:13:09 2021-01-01 00:21:26   \n",
       "4                     B00037 2021-01-01 00:38:31 2021-01-01 00:53:44   \n",
       "...                      ...                 ...                 ...   \n",
       "1154107               B03266 2021-01-31 23:43:03 2021-01-31 23:51:48   \n",
       "1154108               B03284 2021-01-31 23:50:27 2021-02-01 00:48:03   \n",
       "1154109      B03285          2021-01-31 23:13:46 2021-01-31 23:29:58   \n",
       "1154110      B03285          2021-01-31 23:58:03 2021-02-01 00:17:29   \n",
       "1154111               B03321 2021-01-31 23:39:00 2021-02-01 00:15:00   \n",
       "\n",
       "         PUlocationID  DOlocationID SR_Flag Affiliated_base_number  \n",
       "0                 NaN           NaN    None                 B00009  \n",
       "1                 NaN           NaN    None                 B00009  \n",
       "2                 NaN           NaN    None                 B00013  \n",
       "3                 NaN          72.0    None                 B00037  \n",
       "4                 NaN          61.0    None                 B00037  \n",
       "...               ...           ...     ...                    ...  \n",
       "1154107           7.0           7.0    None                 B03266  \n",
       "1154108          44.0          91.0    None                         \n",
       "1154109         171.0         171.0    None        B03285           \n",
       "1154110          15.0          15.0    None        B03285           \n",
       "1154111           NaN           NaN    None                 B03321  \n",
       "\n",
       "[1154112 rows x 7 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fhv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:30:10</td>\n",
       "      <td>2021-01-01 00:36:12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>142</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>8.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.80</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:51:20</td>\n",
       "      <td>2021-01-01 00:52:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>238</td>\n",
       "      <td>151</td>\n",
       "      <td>2</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:43:30</td>\n",
       "      <td>2021-01-01 01:11:06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>132</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>42.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>51.95</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:15:48</td>\n",
       "      <td>2021-01-01 00:31:01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>36.35</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:31:49</td>\n",
       "      <td>2021-01-01 00:48:21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.94</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>68</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>16.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.36</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369764</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-31 23:03:00</td>\n",
       "      <td>2021-01-31 23:33:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>229</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>27.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>38.54</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369765</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-31 23:29:00</td>\n",
       "      <td>2021-01-31 23:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>41</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>32.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0.3</td>\n",
       "      <td>39.50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369766</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-31 23:25:00</td>\n",
       "      <td>2021-01-31 23:38:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>74</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>16.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369767</th>\n",
       "      <td>6</td>\n",
       "      <td>2021-01-31 23:01:06</td>\n",
       "      <td>2021-02-01 00:02:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>265</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>53.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>54.48</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369768</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-31 23:08:29</td>\n",
       "      <td>2021-01-31 23:31:22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>89</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>25.45</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>29.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1369769 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0               1  2021-01-01 00:30:10   2021-01-01 00:36:12              1.0   \n",
       "1               1  2021-01-01 00:51:20   2021-01-01 00:52:19              1.0   \n",
       "2               1  2021-01-01 00:43:30   2021-01-01 01:11:06              1.0   \n",
       "3               1  2021-01-01 00:15:48   2021-01-01 00:31:01              0.0   \n",
       "4               2  2021-01-01 00:31:49   2021-01-01 00:48:21              1.0   \n",
       "...           ...                  ...                   ...              ...   \n",
       "1369764         2  2021-01-31 23:03:00   2021-01-31 23:33:00              NaN   \n",
       "1369765         2  2021-01-31 23:29:00   2021-01-31 23:51:00              NaN   \n",
       "1369766         2  2021-01-31 23:25:00   2021-01-31 23:38:00              NaN   \n",
       "1369767         6  2021-01-31 23:01:06   2021-02-01 00:02:03              NaN   \n",
       "1369768         2  2021-01-31 23:08:29   2021-01-31 23:31:22              NaN   \n",
       "\n",
       "         trip_distance  RatecodeID store_and_fwd_flag  PULocationID  \\\n",
       "0                 2.10         1.0                  N           142   \n",
       "1                 0.20         1.0                  N           238   \n",
       "2                14.70         1.0                  N           132   \n",
       "3                10.60         1.0                  N           138   \n",
       "4                 4.94         1.0                  N            68   \n",
       "...                ...         ...                ...           ...   \n",
       "1369764           8.89         NaN               None           229   \n",
       "1369765           7.43         NaN               None            41   \n",
       "1369766           6.26         NaN               None            74   \n",
       "1369767          19.70         NaN               None           265   \n",
       "1369768           4.68         NaN               None            89   \n",
       "\n",
       "         DOLocationID  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
       "0                  43             2         8.00   3.00      0.5        0.00   \n",
       "1                 151             2         3.00   0.50      0.5        0.00   \n",
       "2                 165             1        42.00   0.50      0.5        8.65   \n",
       "3                 132             1        29.00   0.50      0.5        6.05   \n",
       "4                  33             1        16.50   0.50      0.5        4.06   \n",
       "...               ...           ...          ...    ...      ...         ...   \n",
       "1369764           181             0        27.78   0.00      0.5        7.46   \n",
       "1369765            70             0        32.58   0.00      0.5        0.00   \n",
       "1369766           137             0        16.85   0.00      0.5        3.90   \n",
       "1369767           188             0        53.68   0.00      0.5        0.00   \n",
       "1369768            61             0        25.45   2.75      0.5        0.00   \n",
       "\n",
       "         tolls_amount  improvement_surcharge  total_amount  \\\n",
       "0                0.00                    0.3         11.80   \n",
       "1                0.00                    0.3          4.30   \n",
       "2                0.00                    0.3         51.95   \n",
       "3                0.00                    0.3         36.35   \n",
       "4                0.00                    0.3         24.36   \n",
       "...               ...                    ...           ...   \n",
       "1369764          0.00                    0.3         38.54   \n",
       "1369765          6.12                    0.3         39.50   \n",
       "1369766          0.00                    0.3         24.05   \n",
       "1369767          0.00                    0.3         54.48   \n",
       "1369768          0.00                    0.3         29.00   \n",
       "\n",
       "         congestion_surcharge  \n",
       "0                         2.5  \n",
       "1                         0.0  \n",
       "2                         0.0  \n",
       "3                         0.0  \n",
       "4                         2.5  \n",
       "...                       ...  \n",
       "1369764                   NaN  \n",
       "1369765                   NaN  \n",
       "1369766                   NaN  \n",
       "1369767                   NaN  \n",
       "1369768                   NaN  \n",
       "\n",
       "[1369769 rows x 18 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_df = df[important_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_df['tpep_pickup_datetime']\n",
    "important_df['tpep_pickup_datetime'] = pd.to_datetime(important_df['tpep_pickup_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = int(params['year'])\n",
    "month = int(params['month'])\n",
    "\n",
    "outside_range = important_df[\n",
    "    (important_df['tpep_pickup_datetime'].dt.year != year) |\n",
    "    (important_df['tpep_pickup_datetime'].dt.month != month)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "24 rows were outside the specified year-month and have been filtered.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def check_date_range(df, year, month, date_column='tpep_pickup_datetime'):\n",
    "    \"\"\"\n",
    "    Checks if the dates in the specified column are within the given year and month.\n",
    "    \n",
    "    Args:\n",
    "    - df: The pandas DataFrame containing the data.\n",
    "    - year: The expected year for the data.\n",
    "    - month: The expected month for the data.\n",
    "    - date_column: The column name that contains the datetime data (default is 'tpep_pickup_datetime').\n",
    "    \n",
    "    Returns:\n",
    "    - filtered_df: DataFrame containing rows that match the specified year and month.\n",
    "    - outside_range: DataFrame containing rows outside the specified year and month.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert the date_column to datetime if it's not already in datetime format\n",
    "    df[date_column] = pd.to_datetime(df[date_column])\n",
    "\n",
    "    # Find rows where the year and month do not match\n",
    "    outside_range = df[\n",
    "        (df[date_column].dt.year != year) | \n",
    "        (df[date_column].dt.month != month)\n",
    "    ]\n",
    "    \n",
    "    if not outside_range.empty:\n",
    "        print(True)  # Found data outside the expected range\n",
    "        \n",
    "        # Filter to keep only the rows within the expected year and month\n",
    "        filtered_df = df[\n",
    "            (df[date_column].dt.year == year) & \n",
    "            (df[date_column].dt.month == month)\n",
    "        ]\n",
    "        print(f'{outside_range.shape[0]} rows were outside the specified year-month and have been filtered.')\n",
    "    else:\n",
    "        print(False)  # No data outside the expected range\n",
    "        filtered_df = df  # No filtering needed if all rows match\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:30:10</td>\n",
       "      <td>2021-01-01 00:36:12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>142</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>8.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.80</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:51:20</td>\n",
       "      <td>2021-01-01 00:52:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>238</td>\n",
       "      <td>151</td>\n",
       "      <td>2</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:43:30</td>\n",
       "      <td>2021-01-01 01:11:06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>132</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>42.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>51.95</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:15:48</td>\n",
       "      <td>2021-01-01 00:31:01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>36.35</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:31:49</td>\n",
       "      <td>2021-01-01 00:48:21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.94</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>68</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>16.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.36</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369764</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-31 23:03:00</td>\n",
       "      <td>2021-01-31 23:33:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>229</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>27.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>38.54</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369765</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-31 23:29:00</td>\n",
       "      <td>2021-01-31 23:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>41</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>32.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0.3</td>\n",
       "      <td>39.50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369766</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-31 23:25:00</td>\n",
       "      <td>2021-01-31 23:38:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>74</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>16.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369767</th>\n",
       "      <td>6</td>\n",
       "      <td>2021-01-31 23:01:06</td>\n",
       "      <td>2021-02-01 00:02:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>265</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>53.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>54.48</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369768</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-31 23:08:29</td>\n",
       "      <td>2021-01-31 23:31:22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>89</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>25.45</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>29.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1369769 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0               1  2021-01-01 00:30:10   2021-01-01 00:36:12              1.0   \n",
       "1               1  2021-01-01 00:51:20   2021-01-01 00:52:19              1.0   \n",
       "2               1  2021-01-01 00:43:30   2021-01-01 01:11:06              1.0   \n",
       "3               1  2021-01-01 00:15:48   2021-01-01 00:31:01              0.0   \n",
       "4               2  2021-01-01 00:31:49   2021-01-01 00:48:21              1.0   \n",
       "...           ...                  ...                   ...              ...   \n",
       "1369764         2  2021-01-31 23:03:00   2021-01-31 23:33:00              NaN   \n",
       "1369765         2  2021-01-31 23:29:00   2021-01-31 23:51:00              NaN   \n",
       "1369766         2  2021-01-31 23:25:00   2021-01-31 23:38:00              NaN   \n",
       "1369767         6  2021-01-31 23:01:06   2021-02-01 00:02:03              NaN   \n",
       "1369768         2  2021-01-31 23:08:29   2021-01-31 23:31:22              NaN   \n",
       "\n",
       "         trip_distance  RatecodeID store_and_fwd_flag  PULocationID  \\\n",
       "0                 2.10         1.0                  N           142   \n",
       "1                 0.20         1.0                  N           238   \n",
       "2                14.70         1.0                  N           132   \n",
       "3                10.60         1.0                  N           138   \n",
       "4                 4.94         1.0                  N            68   \n",
       "...                ...         ...                ...           ...   \n",
       "1369764           8.89         NaN               None           229   \n",
       "1369765           7.43         NaN               None            41   \n",
       "1369766           6.26         NaN               None            74   \n",
       "1369767          19.70         NaN               None           265   \n",
       "1369768           4.68         NaN               None            89   \n",
       "\n",
       "         DOLocationID  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
       "0                  43             2         8.00   3.00      0.5        0.00   \n",
       "1                 151             2         3.00   0.50      0.5        0.00   \n",
       "2                 165             1        42.00   0.50      0.5        8.65   \n",
       "3                 132             1        29.00   0.50      0.5        6.05   \n",
       "4                  33             1        16.50   0.50      0.5        4.06   \n",
       "...               ...           ...          ...    ...      ...         ...   \n",
       "1369764           181             0        27.78   0.00      0.5        7.46   \n",
       "1369765            70             0        32.58   0.00      0.5        0.00   \n",
       "1369766           137             0        16.85   0.00      0.5        3.90   \n",
       "1369767           188             0        53.68   0.00      0.5        0.00   \n",
       "1369768            61             0        25.45   2.75      0.5        0.00   \n",
       "\n",
       "         tolls_amount  improvement_surcharge  total_amount  \\\n",
       "0                0.00                    0.3         11.80   \n",
       "1                0.00                    0.3          4.30   \n",
       "2                0.00                    0.3         51.95   \n",
       "3                0.00                    0.3         36.35   \n",
       "4                0.00                    0.3         24.36   \n",
       "...               ...                    ...           ...   \n",
       "1369764          0.00                    0.3         38.54   \n",
       "1369765          6.12                    0.3         39.50   \n",
       "1369766          0.00                    0.3         24.05   \n",
       "1369767          0.00                    0.3         54.48   \n",
       "1369768          0.00                    0.3         29.00   \n",
       "\n",
       "         congestion_surcharge  \n",
       "0                         2.5  \n",
       "1                         0.0  \n",
       "2                         0.0  \n",
       "3                         0.0  \n",
       "4                         2.5  \n",
       "...                       ...  \n",
       "1369764                   NaN  \n",
       "1369765                   NaN  \n",
       "1369766                   NaN  \n",
       "1369767                   NaN  \n",
       "1369768                   NaN  \n",
       "\n",
       "[1369769 rows x 18 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_filtered_data(df, original_name, output_dir='../data/filtered'):\n",
    "    \"\"\"\n",
    "    Saves the filtered DataFrame to a parquet file with a prefix 'filtered_'.\n",
    "    \n",
    "    Args:\n",
    "    - df: The filtered pandas DataFrame.\n",
    "    - original_name: The original name of the data file (used for constructing the output filename).\n",
    "    - output_dir: The directory where the filtered file will be saved (default is '../data/filtered').\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Construct the new filename by adding the prefix 'filtered_' to the original filename\n",
    "    filtered_filename = f'filtered_{original_name}.parquet'\n",
    "    output_path = os.path.join(output_dir, filtered_filename)\n",
    "    \n",
    "    # Save the DataFrame to a parquet file\n",
    "    df.to_parquet(output_path)\n",
    "    print(f'Filtered data saved to {output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "24 rows were outside the specified year-month and have been filtered.\n",
      "Filtered data saved to ../data/filtered/filtered_yellow_tripdata_2021-01.parquet\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "params = {'year': 2021, 'month': 1}\n",
    "columns = ['tpep_pickup_datetime', 'PULocationID']\n",
    "\n",
    "\n",
    "filtered_df = check_date_range(important_df, params['year'], params['month'])\n",
    "# Save the filtered data\n",
    "original_filename = f'yellow_tripdata_{params[\"year\"]}-{params[\"month\"]:02d}'\n",
    "save_filtered_data(filtered_df, original_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def filter_by_date_range(df, year, month, date_column):\n",
    "    \"\"\"\n",
    "    Filters rows in the DataFrame that match the specified year and month in the given date column.\n",
    "    \n",
    "    Args:\n",
    "    - df: The pandas DataFrame containing the data.\n",
    "    - year: The expected year for the data.\n",
    "    - month: The expected month for the data.\n",
    "    - date_column: The column name that contains the datetime data (default is 'pickup_datetime').\n",
    "    \n",
    "    Returns:\n",
    "    - filtered_df: DataFrame containing rows that match the specified year and month.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Rename the datetime column to 'pickup_datetime'\n",
    "    df = df.rename(columns={date_column: 'pickup_datetime'})\n",
    "\n",
    "    # Convert 'pickup_datetime' to datetime\n",
    "    df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])\n",
    "\n",
    "    # Filter rows outside the specified year and month\n",
    "    outside_range = df[\n",
    "        (df['pickup_datetime'].dt.year != year) | \n",
    "        (df['pickup_datetime'].dt.month != month)\n",
    "    ]\n",
    "    \n",
    "    if not outside_range.empty:\n",
    "        print(f\"Found {outside_range.shape[0]} rows outside the specified year-month. Filtering them out.\")\n",
    "        \n",
    "        # Keep only the rows within the specified year and month\n",
    "        filtered_df = df[\n",
    "            (df['pickup_datetime'].dt.year == year) & \n",
    "            (df['pickup_datetime'].dt.month == month)\n",
    "        ]\n",
    "    else:\n",
    "        print('All data within the expected date range.')\n",
    "        filtered_df = df  # No filtering needed if all rows match\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "\n",
    "def select_important_columns(df, file_type):\n",
    "    \"\"\"\n",
    "    Selects important columns for the analysis, renaming columns where necessary,\n",
    "    and removes rows with missing values.\n",
    "    \n",
    "    Args:\n",
    "    - df: The pandas DataFrame.\n",
    "    - file_type: The type of file being processed (e.g., 'fhv_tripdata', 'yellow_tripdata').\n",
    "    \n",
    "    Returns:\n",
    "    - df: DataFrame with only the important columns and no NaN values.\n",
    "    \"\"\"\n",
    "    # Handle the special case for 'fhv_tripdata' where the column name is 'PUlocationID' instead of 'PULocationID'\n",
    "    if file_type == 'fhv_tripdata':\n",
    "        df = df.rename(columns={'PUlocationID': 'PULocationID'})\n",
    "    \n",
    "    # Keep only the important columns ('pickup_datetime' and 'PULocationID')\n",
    "    df = df[['pickup_datetime', 'PULocationID']]\n",
    "    \n",
    "    # Remove rows with NaN values in the important columns\n",
    "    df = df.dropna(subset=['pickup_datetime', 'PULocationID'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def save_filtered_data(df, original_name, output_dir='../data/filtered'):\n",
    "    \"\"\"\n",
    "    Saves the filtered DataFrame to a parquet file with a prefix 'filtered_'.\n",
    "    \n",
    "    Args:\n",
    "    - df: The filtered pandas DataFrame.\n",
    "    - original_name: The original name of the data file (used for constructing the output filename).\n",
    "    - output_dir: The directory where the filtered file will be saved (default is '../data/filtered').\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Construct the new filename by adding the prefix 'filtered_' to the original filename\n",
    "    filtered_filename = f'filtered_{original_name}.parquet'\n",
    "    output_path = os.path.join(output_dir, filtered_filename)\n",
    "    \n",
    "    # Save the DataFrame to a parquet file\n",
    "    df.to_parquet(output_path)\n",
    "    print(f'Filtered data saved to {output_path}')\n",
    "\n",
    "\n",
    "def process_file(filename, input_dir='../data/raw', output_dir='../data/filtered'):\n",
    "    \"\"\"\n",
    "    Processes a single parquet file by filtering data based on date, selecting important columns, \n",
    "    and saving the result.\n",
    "    \n",
    "    Args:\n",
    "    - filename: The name of the file to process.\n",
    "    - input_dir: The directory where the parquet file is located.\n",
    "    - output_dir: The directory where the filtered parquet file will be saved.\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Construct the filtered file name and path\n",
    "        filtered_filename = f'filtered_{filename}'\n",
    "        filtered_file_path = os.path.join(output_dir, filtered_filename)\n",
    "\n",
    "        # Check if the filtered file already exists\n",
    "        if Path(filtered_file_path).exists():\n",
    "            print(f'{filtered_filename} already exists. Skipping processing.')\n",
    "            return  # Skip this file since it's already processed\n",
    "        \n",
    "        # Known patterns and corresponding original date columns\n",
    "        file_patterns = {\n",
    "            'yellow_tripdata': 'tpep_pickup_datetime',\n",
    "            'green_tripdata': 'lpep_pickup_datetime',\n",
    "            'fhv_tripdata': 'pickup_datetime',   # Corrected for fhv files\n",
    "            'fhvhv_tripdata': 'pickup_datetime'\n",
    "        }\n",
    "        \n",
    "        for pattern, original_date_column in file_patterns.items():\n",
    "            if filename.startswith(pattern):\n",
    "                try:\n",
    "                    # Extract year and month from the filename\n",
    "                    parts = filename.split('_')\n",
    "                    file_year, file_month = parts[-1].split('.')[0].split('-')\n",
    "                    file_year = int(file_year)\n",
    "                    file_month = int(file_month)\n",
    "\n",
    "                    # Load the parquet file\n",
    "                    file_path = os.path.join(input_dir, filename)\n",
    "                    df = pd.read_parquet(file_path)\n",
    "\n",
    "                    # Filter rows by date range (year and month)\n",
    "                    df = filter_by_date_range(df, file_year, file_month, original_date_column)\n",
    "                    \n",
    "                    # Select important columns for analysis\n",
    "                    df = select_important_columns(df, pattern)  # Handle column name differences\n",
    "                    \n",
    "                    # Save the filtered DataFrame\n",
    "                    save_filtered_data(df, filename.replace('.parquet', ''), output_dir)\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "                break\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {filename} not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error processing {filename}: {e}\")\n",
    "\n",
    "\n",
    "def process_all_parquet_files_in_directory(input_dir='../data/raw', output_dir='../data/filtered'):\n",
    "    \"\"\"\n",
    "    Processes all parquet files in the input directory that follow the known patterns.\n",
    "    \n",
    "    Args:\n",
    "    - input_dir: The directory where the raw parquet files are located.\n",
    "    - output_dir: The directory where the filtered parquet files will be saved.\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith('.parquet'):\n",
    "            try:\n",
    "                process_file(filename, input_dir, output_dir)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {filename}: {e}\")\n",
    "                continue\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the parquet processing from ../data/raw to ../data/filtered...\n",
      "filtered_fhvhv_tripdata_2022-03.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2023-07.parquet already exists. Skipping processing.\n",
      "filtered_fhv_tripdata_2021-12.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2021-08.parquet already exists. Skipping processing.\n",
      "filtered_green_tripdata_2021-06.parquet already exists. Skipping processing.\n",
      "filtered_fhvhv_tripdata_2021-07.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2022-04.parquet already exists. Skipping processing.\n",
      "filtered_fhvhv_tripdata_2021-12.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2022-05.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2023-10.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2021-03.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2022-12.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2021-02.parquet already exists. Skipping processing.\n",
      "filtered_fhv_tripdata_2022-02.parquet already exists. Skipping processing.\n",
      "filtered_fhvhv_tripdata_2021-08.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2023-05.parquet already exists. Skipping processing.\n",
      "filtered_fhv_tripdata_2022-03.parquet already exists. Skipping processing.\n",
      "filtered_fhvhv_tripdata_2021-10.parquet already exists. Skipping processing.\n",
      "filtered_fhv_tripdata_2022-05.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2022-02.parquet already exists. Skipping processing.\n",
      "filtered_fhvhv_tripdata_2022-01.parquet already exists. Skipping processing.\n",
      "filtered_green_tripdata_2021-01.parquet already exists. Skipping processing.\n",
      "filtered_green_tripdata_2021-10.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2023-12.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2021-05.parquet already exists. Skipping processing.\n",
      "filtered_green_tripdata_2021-09.parquet already exists. Skipping processing.\n",
      "filtered_fhvhv_tripdata_2021-02.parquet already exists. Skipping processing.\n",
      "filtered_fhv_tripdata_2021-05.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2023-06.parquet already exists. Skipping processing.\n",
      "filtered_fhv_tripdata_2021-01.parquet already exists. Skipping processing.\n",
      "filtered_fhvhv_tripdata_2021-01.parquet already exists. Skipping processing.\n",
      "filtered_green_tripdata_2021-12.parquet already exists. Skipping processing.\n",
      "filtered_fhv_tripdata_2021-08.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2023-11.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2021-01.parquet already exists. Skipping processing.\n",
      "filtered_fhv_tripdata_2022-07.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2021-11.parquet already exists. Skipping processing.\n",
      "filtered_green_tripdata_2022-07.parquet already exists. Skipping processing.\n",
      "filtered_green_tripdata_2022-06.parquet already exists. Skipping processing.\n",
      "filtered_fhv_tripdata_2021-06.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2022-09.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2021-04.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2022-08.parquet already exists. Skipping processing.\n",
      "filtered_green_tripdata_2021-05.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2023-03.parquet already exists. Skipping processing.\n",
      "filtered_fhvhv_tripdata_2022-06.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2023-01.parquet already exists. Skipping processing.\n",
      "filtered_fhv_tripdata_2021-07.parquet already exists. Skipping processing.\n",
      "filtered_fhvhv_tripdata_2022-04.parquet already exists. Skipping processing.\n",
      "filtered_green_tripdata_2022-03.parquet already exists. Skipping processing.\n",
      "filtered_green_tripdata_2021-04.parquet already exists. Skipping processing.\n",
      "filtered_green_tripdata_2022-05.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2022-03.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2021-12.parquet already exists. Skipping processing.\n",
      "filtered_fhv_tripdata_2022-04.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2021-06.parquet already exists. Skipping processing.\n",
      "filtered_fhv_tripdata_2021-02.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2021-09.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2022-01.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2023-04.parquet already exists. Skipping processing.\n",
      "filtered_green_tripdata_2021-02.parquet already exists. Skipping processing.\n",
      "filtered_fhvhv_tripdata_2021-06.parquet already exists. Skipping processing.\n",
      "filtered_fhvhv_tripdata_2021-11.parquet already exists. Skipping processing.\n",
      "filtered_fhvhv_tripdata_2022-05.parquet already exists. Skipping processing.\n",
      "filtered_green_tripdata_2021-08.parquet already exists. Skipping processing.\n",
      "filtered_fhv_tripdata_2021-04.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2023-08.parquet already exists. Skipping processing.\n",
      "filtered_fhvhv_tripdata_2021-03.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2023-02.parquet already exists. Skipping processing.\n",
      "filtered_green_tripdata_2022-04.parquet already exists. Skipping processing.\n",
      "filtered_fhv_tripdata_2021-03.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2022-10.parquet already exists. Skipping processing.\n",
      "filtered_green_tripdata_2021-11.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2023-09.parquet already exists. Skipping processing.\n",
      "filtered_fhv_tripdata_2021-10.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2021-07.parquet already exists. Skipping processing.\n",
      "filtered_green_tripdata_2021-03.parquet already exists. Skipping processing.\n",
      "filtered_fhvhv_tripdata_2021-04.parquet already exists. Skipping processing.\n",
      "filtered_fhv_tripdata_2021-09.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2022-06.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2021-10.parquet already exists. Skipping processing.\n",
      "filtered_fhvhv_tripdata_2021-09.parquet already exists. Skipping processing.\n",
      "filtered_fhvhv_tripdata_2022-02.parquet already exists. Skipping processing.\n",
      "filtered_green_tripdata_2022-01.parquet already exists. Skipping processing.\n",
      "filtered_fhv_tripdata_2022-01.parquet already exists. Skipping processing.\n",
      "filtered_fhv_tripdata_2022-06.parquet already exists. Skipping processing.\n",
      "filtered_fhvhv_tripdata_2021-05.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2022-07.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2022-11.parquet already exists. Skipping processing.\n",
      "filtered_green_tripdata_2022-02.parquet already exists. Skipping processing.\n",
      "filtered_fhv_tripdata_2021-11.parquet already exists. Skipping processing.\n",
      "filtered_green_tripdata_2021-07.parquet already exists. Skipping processing.\n",
      "Processing complete. Check ../data/filtered for the filtered files.\n"
     ]
    }
   ],
   "source": [
    "# Test script for processing parquet files\n",
    "\n",
    "# Directory setup for test (change if needed)\n",
    "input_directory = '../data/raw'\n",
    "output_directory = '../data/filtered'\n",
    "\n",
    "# Assuming you have some .parquet files in the input directory\n",
    "# Example: 'yellow_tripdata_2021-01.parquet', 'green_tripdata_2021-01.parquet'\n",
    "\n",
    "def test_parquet_processing():\n",
    "    print(f\"Starting the parquet processing from {input_directory} to {output_directory}...\")\n",
    "\n",
    "    # Call the function to process all files in the directory\n",
    "    process_all_parquet_files_in_directory(input_dir=input_directory, output_dir=output_directory)\n",
    "\n",
    "    print(f\"Processing complete. Check {output_directory} for the filtered files.\")\n",
    "\n",
    "# Run the test\n",
    "if __name__ == \"__main__\":\n",
    "    test_parquet_processing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../data/filtered/filtered_yellow_tripdata_2021-01.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01 00:30:10</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-01 00:51:20</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-01 00:43:30</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-01 00:15:48</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-01 00:31:49</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369764</th>\n",
       "      <td>2021-01-31 23:03:00</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369765</th>\n",
       "      <td>2021-01-31 23:29:00</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369766</th>\n",
       "      <td>2021-01-31 23:25:00</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369767</th>\n",
       "      <td>2021-01-31 23:01:06</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369768</th>\n",
       "      <td>2021-01-31 23:08:29</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1369745 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pickup_datetime  PULocationID\n",
       "0       2021-01-01 00:30:10           142\n",
       "1       2021-01-01 00:51:20           238\n",
       "2       2021-01-01 00:43:30           132\n",
       "3       2021-01-01 00:15:48           138\n",
       "4       2021-01-01 00:31:49            68\n",
       "...                     ...           ...\n",
       "1369764 2021-01-31 23:03:00           229\n",
       "1369765 2021-01-31 23:29:00            41\n",
       "1369766 2021-01-31 23:25:00            74\n",
       "1369767 2021-01-31 23:01:06           265\n",
       "1369768 2021-01-31 23:08:29            89\n",
       "\n",
       "[1369745 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "src-k1b3gFX9-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
