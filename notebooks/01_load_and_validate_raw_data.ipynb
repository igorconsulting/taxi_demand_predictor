{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yellow_tripdata_2021-01.parquet already exists. Skipping download.\n",
      "green_tripdata_2021-01.parquet already exists. Skipping download.\n",
      "fhv_tripdata_2021-01.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-01.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-02.parquet already exists. Skipping download.\n",
      "green_tripdata_2021-02.parquet already exists. Skipping download.\n",
      "fhv_tripdata_2021-02.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-02.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-03.parquet already exists. Skipping download.\n",
      "green_tripdata_2021-03.parquet already exists. Skipping download.\n",
      "fhv_tripdata_2021-03.parquet already exists. Skipping download.\n",
      "fhvhv_tripdata_2021-03.parquet already exists. Skipping download.\n",
      "yellow_tripdata_2021-04.parquet already exists. Skipping download.\n",
      "green_tripdata_2021-04.parquet downloaded successfully to ../data/raw\n",
      "fhv_tripdata_2021-04.parquet downloaded successfully to ../data/raw\n",
      "fhvhv_tripdata_2021-04.parquet downloaded successfully to ../data/raw\n",
      "yellow_tripdata_2021-05.parquet already exists. Skipping download.\n",
      "green_tripdata_2021-05.parquet downloaded successfully to ../data/raw\n",
      "fhv_tripdata_2021-05.parquet downloaded successfully to ../data/raw\n",
      "fhvhv_tripdata_2021-05.parquet downloaded successfully to ../data/raw\n",
      "yellow_tripdata_2021-06.parquet already exists. Skipping download.\n",
      "green_tripdata_2021-06.parquet downloaded successfully to ../data/raw\n",
      "fhv_tripdata_2021-06.parquet downloaded successfully to ../data/raw\n",
      "fhvhv_tripdata_2021-06.parquet downloaded successfully to ../data/raw\n",
      "yellow_tripdata_2021-07.parquet already exists. Skipping download.\n",
      "green_tripdata_2021-07.parquet downloaded successfully to ../data/raw\n",
      "fhv_tripdata_2021-07.parquet downloaded successfully to ../data/raw\n",
      "fhvhv_tripdata_2021-07.parquet downloaded successfully to ../data/raw\n",
      "yellow_tripdata_2021-08.parquet already exists. Skipping download.\n",
      "green_tripdata_2021-08.parquet downloaded successfully to ../data/raw\n",
      "fhv_tripdata_2021-08.parquet downloaded successfully to ../data/raw\n",
      "fhvhv_tripdata_2021-08.parquet downloaded successfully to ../data/raw\n",
      "yellow_tripdata_2021-09.parquet already exists. Skipping download.\n",
      "green_tripdata_2021-09.parquet downloaded successfully to ../data/raw\n",
      "fhv_tripdata_2021-09.parquet downloaded successfully to ../data/raw\n",
      "fhvhv_tripdata_2021-09.parquet downloaded successfully to ../data/raw\n",
      "yellow_tripdata_2021-10.parquet already exists. Skipping download.\n",
      "green_tripdata_2021-10.parquet downloaded successfully to ../data/raw\n",
      "fhv_tripdata_2021-10.parquet downloaded successfully to ../data/raw\n",
      "fhvhv_tripdata_2021-10.parquet downloaded successfully to ../data/raw\n",
      "yellow_tripdata_2021-11.parquet already exists. Skipping download.\n",
      "green_tripdata_2021-11.parquet downloaded successfully to ../data/raw\n",
      "fhv_tripdata_2021-11.parquet downloaded successfully to ../data/raw\n",
      "fhvhv_tripdata_2021-11.parquet downloaded successfully to ../data/raw\n",
      "yellow_tripdata_2021-12.parquet already exists. Skipping download.\n",
      "green_tripdata_2021-12.parquet downloaded successfully to ../data/raw\n",
      "fhv_tripdata_2021-12.parquet downloaded successfully to ../data/raw\n",
      "fhvhv_tripdata_2021-12.parquet downloaded successfully to ../data/raw\n",
      "yellow_tripdata_2022-01.parquet already exists. Skipping download.\n",
      "green_tripdata_2022-01.parquet downloaded successfully to ../data/raw\n",
      "fhv_tripdata_2022-01.parquet downloaded successfully to ../data/raw\n",
      "fhvhv_tripdata_2022-01.parquet downloaded successfully to ../data/raw\n",
      "yellow_tripdata_2022-02.parquet already exists. Skipping download.\n",
      "green_tripdata_2022-02.parquet downloaded successfully to ../data/raw\n",
      "fhv_tripdata_2022-02.parquet downloaded successfully to ../data/raw\n",
      "fhvhv_tripdata_2022-02.parquet downloaded successfully to ../data/raw\n",
      "yellow_tripdata_2022-03.parquet already exists. Skipping download.\n",
      "green_tripdata_2022-03.parquet downloaded successfully to ../data/raw\n",
      "fhv_tripdata_2022-03.parquet downloaded successfully to ../data/raw\n",
      "fhvhv_tripdata_2022-03.parquet downloaded successfully to ../data/raw\n",
      "yellow_tripdata_2022-04.parquet already exists. Skipping download.\n",
      "green_tripdata_2022-04.parquet downloaded successfully to ../data/raw\n",
      "fhv_tripdata_2022-04.parquet downloaded successfully to ../data/raw\n",
      "fhvhv_tripdata_2022-04.parquet downloaded successfully to ../data/raw\n",
      "yellow_tripdata_2022-05.parquet already exists. Skipping download.\n",
      "green_tripdata_2022-05.parquet downloaded successfully to ../data/raw\n",
      "fhv_tripdata_2022-05.parquet downloaded successfully to ../data/raw\n",
      "fhvhv_tripdata_2022-05.parquet downloaded successfully to ../data/raw\n",
      "yellow_tripdata_2022-06.parquet already exists. Skipping download.\n",
      "green_tripdata_2022-06.parquet downloaded successfully to ../data/raw\n",
      "fhv_tripdata_2022-06.parquet downloaded successfully to ../data/raw\n",
      "fhvhv_tripdata_2022-06.parquet downloaded successfully to ../data/raw\n",
      "yellow_tripdata_2022-07.parquet already exists. Skipping download.\n",
      "green_tripdata_2022-07.parquet downloaded successfully to ../data/raw\n",
      "fhv_tripdata_2022-07.parquet downloaded successfully to ../data/raw\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 71\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m years:\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m month \u001b[38;5;129;01min\u001b[39;00m months:\n\u001b[0;32m---> 71\u001b[0m         \u001b[43mnyc_data_extrator\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonth\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[75], line 63\u001b[0m, in \u001b[0;36mnyc_data_extrator\u001b[0;34m(year, month)\u001b[0m\n\u001b[1;32m     61\u001b[0m download_green_monthly_data(year, month)\n\u001b[1;32m     62\u001b[0m download_fhv_monthly_data(year, month)\n\u001b[0;32m---> 63\u001b[0m \u001b[43mdownload_fhvhv_monthly_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonth\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[75], line 57\u001b[0m, in \u001b[0;36mdownload_fhvhv_monthly_data\u001b[0;34m(year, month)\u001b[0m\n\u001b[1;32m     55\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     56\u001b[0m file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfhvhv_tripdata_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 57\u001b[0m \u001b[43mfetch_raw_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[75], line 27\u001b[0m, in \u001b[0;36mfetch_raw_data\u001b[0;34m(url, file_name, repo_dir)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Attempt to download the file\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Check if the download was successful\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-k1b3gFX9-py3.10/lib/python3.10/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-k1b3gFX9-py3.10/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-k1b3gFX9-py3.10/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-k1b3gFX9-py3.10/lib/python3.10/site-packages/requests/sessions.py:746\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[0;32m--> 746\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-k1b3gFX9-py3.10/lib/python3.10/site-packages/requests/models.py:902\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    900\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    901\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 902\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-k1b3gFX9-py3.10/lib/python3.10/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-k1b3gFX9-py3.10/lib/python3.10/site-packages/urllib3/response.py:1060\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1059\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1060\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1062\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m   1063\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-k1b3gFX9-py3.10/lib/python3.10/site-packages/urllib3/response.py:949\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[1;32m    947\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[0;32m--> 949\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    951\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-k1b3gFX9-py3.10/lib/python3.10/site-packages/urllib3/response.py:873\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    870\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 873\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    874\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[1;32m    875\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[1;32m    876\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    883\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-k1b3gFX9-py3.10/lib/python3.10/site-packages/urllib3/response.py:856\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 466\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1303\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1300\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1301\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1302\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1305\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1159\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1159\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1161\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fetch the file from the server\n",
    "\n",
    "import requests\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def fetch_raw_data(url, file_name, repo_dir='../data/raw'):\n",
    "    \"\"\"\n",
    "    Downloads the file from the provided URL if it doesn't already exist in the directory.\n",
    "    \n",
    "    Args:\n",
    "    - url: The URL from which the file will be downloaded.\n",
    "    - file_name: The name with which the file will be saved.\n",
    "    - repo_dir: The directory where the file will be saved (default: '../data/raw').\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    file_path = Path(repo_dir) / file_name\n",
    "\n",
    "    # Check if the file already exists\n",
    "    if file_path.exists():\n",
    "        print(f'{file_name} already exists. Skipping download.')\n",
    "        return\n",
    "\n",
    "    # Attempt to download the file\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the download was successful\n",
    "    if response.status_code == 200:\n",
    "        Path(repo_dir).mkdir(parents=True, exist_ok=True)\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f'{file_name} downloaded successfully to {repo_dir}')\n",
    "    else:\n",
    "        raise Exception(f'Status code error: {response.status_code} - File not available!')\n",
    "\n",
    "\n",
    "def download_yellow_monthly_data(year, month):\n",
    "    url = f'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{year}-{month}.parquet'\n",
    "    file_name = f'yellow_tripdata_{year}-{month}.parquet'\n",
    "    fetch_raw_data(url, file_name)\n",
    "\n",
    "def download_green_monthly_data(year, month):\n",
    "    url = f'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_{year}-{month}.parquet'\n",
    "    file_name = f'green_tripdata_{year}-{month}.parquet'\n",
    "    fetch_raw_data(url, file_name)\n",
    "\n",
    "def download_fhv_monthly_data(year, month):\n",
    "    url = f'https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_{year}-{month}.parquet'\n",
    "    file_name = f'fhv_tripdata_{year}-{month}.parquet'\n",
    "    fetch_raw_data(url, file_name)\n",
    "\n",
    "def download_fhvhv_monthly_data(year, month):\n",
    "    url = f'https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_{year}-{month}.parquet'\n",
    "    file_name = f'fhvhv_tripdata_{year}-{month}.parquet'\n",
    "    fetch_raw_data(url, file_name)\n",
    "\n",
    "def nyc_data_extrator(year, month):\n",
    "    download_yellow_monthly_data(year, month)\n",
    "    download_green_monthly_data(year, month)\n",
    "    download_fhv_monthly_data(year, month)\n",
    "    download_fhvhv_monthly_data(year, month)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    years = ['2021', '2022', '2023']\n",
    "    months = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "\n",
    "    for year in years:\n",
    "        for month in months:\n",
    "            nyc_data_extrator(year, month)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag', 'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount', 'congestion_surcharge'\n",
    "    ]\n",
    "\n",
    "important_columns = ['tpep_pickup_datetime', 'PULocationID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "params = {'year': '2021', 'month': '01'}\n",
    "\n",
    "df = pd.read_parquet('../data/raw/yellow_tripdata_{year}-{month}.parquet'.format(**params), columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green = pd.read_parquet('../data/raw/green_tripdata_{year}-{month}.parquet'.format(**params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:15:56</td>\n",
       "      <td>2021-01-01 00:19:52</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43</td>\n",
       "      <td>151</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.01</td>\n",
       "      <td>5.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.80</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:25:59</td>\n",
       "      <td>2021-01-01 00:34:44</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>166</td>\n",
       "      <td>239</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.53</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:45:57</td>\n",
       "      <td>2021-01-01 00:51:55</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-12-31 23:57:51</td>\n",
       "      <td>2021-01-01 00:04:56</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>168</td>\n",
       "      <td>75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.99</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:16:36</td>\n",
       "      <td>2021-01-01 00:16:40</td>\n",
       "      <td>N</td>\n",
       "      <td>2.0</td>\n",
       "      <td>265</td>\n",
       "      <td>265</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-52.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-52.80</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76513</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-31 21:38:00</td>\n",
       "      <td>2021-01-31 22:16:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.63</td>\n",
       "      <td>56.23</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.12</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>65.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76514</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-31 22:43:00</td>\n",
       "      <td>2021-01-31 23:21:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.36</td>\n",
       "      <td>46.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.20</td>\n",
       "      <td>6.12</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>65.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76515</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-31 22:16:00</td>\n",
       "      <td>2021-01-31 22:27:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.50</td>\n",
       "      <td>18.95</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>22.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76516</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-31 23:10:00</td>\n",
       "      <td>2021-01-31 23:37:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>168</td>\n",
       "      <td>215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.48</td>\n",
       "      <td>48.87</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.12</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>58.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76517</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-31 23:25:00</td>\n",
       "      <td>2021-01-31 23:35:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119</td>\n",
       "      <td>244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.81</td>\n",
       "      <td>15.45</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>18.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76518 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
       "0             2  2021-01-01 00:15:56   2021-01-01 00:19:52                  N   \n",
       "1             2  2021-01-01 00:25:59   2021-01-01 00:34:44                  N   \n",
       "2             2  2021-01-01 00:45:57   2021-01-01 00:51:55                  N   \n",
       "3             2  2020-12-31 23:57:51   2021-01-01 00:04:56                  N   \n",
       "4             2  2021-01-01 00:16:36   2021-01-01 00:16:40                  N   \n",
       "...         ...                  ...                   ...                ...   \n",
       "76513         2  2021-01-31 21:38:00   2021-01-31 22:16:00               None   \n",
       "76514         2  2021-01-31 22:43:00   2021-01-31 23:21:00               None   \n",
       "76515         2  2021-01-31 22:16:00   2021-01-31 22:27:00               None   \n",
       "76516         2  2021-01-31 23:10:00   2021-01-31 23:37:00               None   \n",
       "76517         2  2021-01-31 23:25:00   2021-01-31 23:35:00               None   \n",
       "\n",
       "       RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
       "0             1.0            43           151              1.0           1.01   \n",
       "1             1.0           166           239              1.0           2.53   \n",
       "2             1.0            41            42              1.0           1.12   \n",
       "3             1.0           168            75              1.0           1.99   \n",
       "4             2.0           265           265              3.0           0.00   \n",
       "...           ...           ...           ...              ...            ...   \n",
       "76513         NaN            81            90              NaN          17.63   \n",
       "76514         NaN            35           213              NaN          18.36   \n",
       "76515         NaN            74            69              NaN           2.50   \n",
       "76516         NaN           168           215              NaN          14.48   \n",
       "76517         NaN           119           244              NaN           1.81   \n",
       "\n",
       "       fare_amount  extra  mta_tax  tip_amount  tolls_amount ehail_fee  \\\n",
       "0             5.50   0.50      0.5        0.00          0.00      None   \n",
       "1            10.00   0.50      0.5        2.81          0.00      None   \n",
       "2             6.00   0.50      0.5        1.00          0.00      None   \n",
       "3             8.00   0.50      0.5        0.00          0.00      None   \n",
       "4           -52.00   0.00     -0.5        0.00          0.00      None   \n",
       "...            ...    ...      ...         ...           ...       ...   \n",
       "76513        56.23   2.75      0.0        0.00          6.12      None   \n",
       "76514        46.66   0.00      0.0       12.20          6.12      None   \n",
       "76515        18.95   2.75      0.0        0.00          0.00      None   \n",
       "76516        48.87   2.75      0.0        0.00          6.12      None   \n",
       "76517        15.45   2.75      0.0        0.00          0.00      None   \n",
       "\n",
       "       improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
       "0                        0.3          6.80           2.0        1.0   \n",
       "1                        0.3         16.86           1.0        1.0   \n",
       "2                        0.3          8.30           1.0        1.0   \n",
       "3                        0.3          9.30           2.0        1.0   \n",
       "4                       -0.3        -52.80           3.0        1.0   \n",
       "...                      ...           ...           ...        ...   \n",
       "76513                    0.3         65.40           NaN        NaN   \n",
       "76514                    0.3         65.28           NaN        NaN   \n",
       "76515                    0.3         22.00           NaN        NaN   \n",
       "76516                    0.3         58.04           NaN        NaN   \n",
       "76517                    0.3         18.50           NaN        NaN   \n",
       "\n",
       "       congestion_surcharge  \n",
       "0                      0.00  \n",
       "1                      2.75  \n",
       "2                      0.00  \n",
       "3                      0.00  \n",
       "4                      0.00  \n",
       "...                     ...  \n",
       "76513                   NaN  \n",
       "76514                   NaN  \n",
       "76515                   NaN  \n",
       "76516                   NaN  \n",
       "76517                   NaN  \n",
       "\n",
       "[76518 rows x 20 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fhv = pd.read_parquet('../data/raw/fhv_tripdata_{year}-{month}.parquet'.format(**params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropOff_datetime</th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2021-01-01 00:27:00</td>\n",
       "      <td>2021-01-01 00:44:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2021-01-01 00:50:00</td>\n",
       "      <td>2021-01-01 01:07:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00013</td>\n",
       "      <td>2021-01-01 00:01:00</td>\n",
       "      <td>2021-01-01 01:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B00013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-01-01 00:13:09</td>\n",
       "      <td>2021-01-01 00:21:26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-01-01 00:38:31</td>\n",
       "      <td>2021-01-01 00:53:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154107</th>\n",
       "      <td>B03266</td>\n",
       "      <td>2021-01-31 23:43:03</td>\n",
       "      <td>2021-01-31 23:51:48</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B03266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154108</th>\n",
       "      <td>B03284</td>\n",
       "      <td>2021-01-31 23:50:27</td>\n",
       "      <td>2021-02-01 00:48:03</td>\n",
       "      <td>44.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154109</th>\n",
       "      <td>B03285</td>\n",
       "      <td>2021-01-31 23:13:46</td>\n",
       "      <td>2021-01-31 23:29:58</td>\n",
       "      <td>171.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B03285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154110</th>\n",
       "      <td>B03285</td>\n",
       "      <td>2021-01-31 23:58:03</td>\n",
       "      <td>2021-02-01 00:17:29</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B03285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154111</th>\n",
       "      <td>B03321</td>\n",
       "      <td>2021-01-31 23:39:00</td>\n",
       "      <td>2021-02-01 00:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B03321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1154112 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        dispatching_base_num     pickup_datetime    dropOff_datetime  \\\n",
       "0                     B00009 2021-01-01 00:27:00 2021-01-01 00:44:00   \n",
       "1                     B00009 2021-01-01 00:50:00 2021-01-01 01:07:00   \n",
       "2                     B00013 2021-01-01 00:01:00 2021-01-01 01:51:00   \n",
       "3                     B00037 2021-01-01 00:13:09 2021-01-01 00:21:26   \n",
       "4                     B00037 2021-01-01 00:38:31 2021-01-01 00:53:44   \n",
       "...                      ...                 ...                 ...   \n",
       "1154107               B03266 2021-01-31 23:43:03 2021-01-31 23:51:48   \n",
       "1154108               B03284 2021-01-31 23:50:27 2021-02-01 00:48:03   \n",
       "1154109      B03285          2021-01-31 23:13:46 2021-01-31 23:29:58   \n",
       "1154110      B03285          2021-01-31 23:58:03 2021-02-01 00:17:29   \n",
       "1154111               B03321 2021-01-31 23:39:00 2021-02-01 00:15:00   \n",
       "\n",
       "         PUlocationID  DOlocationID SR_Flag Affiliated_base_number  \n",
       "0                 NaN           NaN    None                 B00009  \n",
       "1                 NaN           NaN    None                 B00009  \n",
       "2                 NaN           NaN    None                 B00013  \n",
       "3                 NaN          72.0    None                 B00037  \n",
       "4                 NaN          61.0    None                 B00037  \n",
       "...               ...           ...     ...                    ...  \n",
       "1154107           7.0           7.0    None                 B03266  \n",
       "1154108          44.0          91.0    None                         \n",
       "1154109         171.0         171.0    None        B03285           \n",
       "1154110          15.0          15.0    None        B03285           \n",
       "1154111           NaN           NaN    None                 B03321  \n",
       "\n",
       "[1154112 rows x 7 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fhv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fhv = pd.read_parquet('../data/raw/fhv_tripdata_{year}-{month}.parquet'.format(**params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropOff_datetime</th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2021-01-01 00:27:00</td>\n",
       "      <td>2021-01-01 00:44:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2021-01-01 00:50:00</td>\n",
       "      <td>2021-01-01 01:07:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00013</td>\n",
       "      <td>2021-01-01 00:01:00</td>\n",
       "      <td>2021-01-01 01:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B00013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-01-01 00:13:09</td>\n",
       "      <td>2021-01-01 00:21:26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00037</td>\n",
       "      <td>2021-01-01 00:38:31</td>\n",
       "      <td>2021-01-01 00:53:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154107</th>\n",
       "      <td>B03266</td>\n",
       "      <td>2021-01-31 23:43:03</td>\n",
       "      <td>2021-01-31 23:51:48</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B03266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154108</th>\n",
       "      <td>B03284</td>\n",
       "      <td>2021-01-31 23:50:27</td>\n",
       "      <td>2021-02-01 00:48:03</td>\n",
       "      <td>44.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154109</th>\n",
       "      <td>B03285</td>\n",
       "      <td>2021-01-31 23:13:46</td>\n",
       "      <td>2021-01-31 23:29:58</td>\n",
       "      <td>171.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B03285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154110</th>\n",
       "      <td>B03285</td>\n",
       "      <td>2021-01-31 23:58:03</td>\n",
       "      <td>2021-02-01 00:17:29</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>None</td>\n",
       "      <td>B03285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154111</th>\n",
       "      <td>B03321</td>\n",
       "      <td>2021-01-31 23:39:00</td>\n",
       "      <td>2021-02-01 00:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>B03321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1154112 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        dispatching_base_num     pickup_datetime    dropOff_datetime  \\\n",
       "0                     B00009 2021-01-01 00:27:00 2021-01-01 00:44:00   \n",
       "1                     B00009 2021-01-01 00:50:00 2021-01-01 01:07:00   \n",
       "2                     B00013 2021-01-01 00:01:00 2021-01-01 01:51:00   \n",
       "3                     B00037 2021-01-01 00:13:09 2021-01-01 00:21:26   \n",
       "4                     B00037 2021-01-01 00:38:31 2021-01-01 00:53:44   \n",
       "...                      ...                 ...                 ...   \n",
       "1154107               B03266 2021-01-31 23:43:03 2021-01-31 23:51:48   \n",
       "1154108               B03284 2021-01-31 23:50:27 2021-02-01 00:48:03   \n",
       "1154109      B03285          2021-01-31 23:13:46 2021-01-31 23:29:58   \n",
       "1154110      B03285          2021-01-31 23:58:03 2021-02-01 00:17:29   \n",
       "1154111               B03321 2021-01-31 23:39:00 2021-02-01 00:15:00   \n",
       "\n",
       "         PUlocationID  DOlocationID SR_Flag Affiliated_base_number  \n",
       "0                 NaN           NaN    None                 B00009  \n",
       "1                 NaN           NaN    None                 B00009  \n",
       "2                 NaN           NaN    None                 B00013  \n",
       "3                 NaN          72.0    None                 B00037  \n",
       "4                 NaN          61.0    None                 B00037  \n",
       "...               ...           ...     ...                    ...  \n",
       "1154107           7.0           7.0    None                 B03266  \n",
       "1154108          44.0          91.0    None                         \n",
       "1154109         171.0         171.0    None        B03285           \n",
       "1154110          15.0          15.0    None        B03285           \n",
       "1154111           NaN           NaN    None                 B03321  \n",
       "\n",
       "[1154112 rows x 7 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fhv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:30:10</td>\n",
       "      <td>2021-01-01 00:36:12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>142</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>8.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.80</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:51:20</td>\n",
       "      <td>2021-01-01 00:52:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>238</td>\n",
       "      <td>151</td>\n",
       "      <td>2</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:43:30</td>\n",
       "      <td>2021-01-01 01:11:06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>132</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>42.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>51.95</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:15:48</td>\n",
       "      <td>2021-01-01 00:31:01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>36.35</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:31:49</td>\n",
       "      <td>2021-01-01 00:48:21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.94</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>68</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>16.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.36</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369764</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-31 23:03:00</td>\n",
       "      <td>2021-01-31 23:33:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>229</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>27.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>38.54</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369765</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-31 23:29:00</td>\n",
       "      <td>2021-01-31 23:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>41</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>32.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0.3</td>\n",
       "      <td>39.50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369766</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-31 23:25:00</td>\n",
       "      <td>2021-01-31 23:38:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>74</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>16.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369767</th>\n",
       "      <td>6</td>\n",
       "      <td>2021-01-31 23:01:06</td>\n",
       "      <td>2021-02-01 00:02:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>265</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>53.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>54.48</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369768</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-31 23:08:29</td>\n",
       "      <td>2021-01-31 23:31:22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>89</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>25.45</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>29.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1369769 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0               1  2021-01-01 00:30:10   2021-01-01 00:36:12              1.0   \n",
       "1               1  2021-01-01 00:51:20   2021-01-01 00:52:19              1.0   \n",
       "2               1  2021-01-01 00:43:30   2021-01-01 01:11:06              1.0   \n",
       "3               1  2021-01-01 00:15:48   2021-01-01 00:31:01              0.0   \n",
       "4               2  2021-01-01 00:31:49   2021-01-01 00:48:21              1.0   \n",
       "...           ...                  ...                   ...              ...   \n",
       "1369764         2  2021-01-31 23:03:00   2021-01-31 23:33:00              NaN   \n",
       "1369765         2  2021-01-31 23:29:00   2021-01-31 23:51:00              NaN   \n",
       "1369766         2  2021-01-31 23:25:00   2021-01-31 23:38:00              NaN   \n",
       "1369767         6  2021-01-31 23:01:06   2021-02-01 00:02:03              NaN   \n",
       "1369768         2  2021-01-31 23:08:29   2021-01-31 23:31:22              NaN   \n",
       "\n",
       "         trip_distance  RatecodeID store_and_fwd_flag  PULocationID  \\\n",
       "0                 2.10         1.0                  N           142   \n",
       "1                 0.20         1.0                  N           238   \n",
       "2                14.70         1.0                  N           132   \n",
       "3                10.60         1.0                  N           138   \n",
       "4                 4.94         1.0                  N            68   \n",
       "...                ...         ...                ...           ...   \n",
       "1369764           8.89         NaN               None           229   \n",
       "1369765           7.43         NaN               None            41   \n",
       "1369766           6.26         NaN               None            74   \n",
       "1369767          19.70         NaN               None           265   \n",
       "1369768           4.68         NaN               None            89   \n",
       "\n",
       "         DOLocationID  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
       "0                  43             2         8.00   3.00      0.5        0.00   \n",
       "1                 151             2         3.00   0.50      0.5        0.00   \n",
       "2                 165             1        42.00   0.50      0.5        8.65   \n",
       "3                 132             1        29.00   0.50      0.5        6.05   \n",
       "4                  33             1        16.50   0.50      0.5        4.06   \n",
       "...               ...           ...          ...    ...      ...         ...   \n",
       "1369764           181             0        27.78   0.00      0.5        7.46   \n",
       "1369765            70             0        32.58   0.00      0.5        0.00   \n",
       "1369766           137             0        16.85   0.00      0.5        3.90   \n",
       "1369767           188             0        53.68   0.00      0.5        0.00   \n",
       "1369768            61             0        25.45   2.75      0.5        0.00   \n",
       "\n",
       "         tolls_amount  improvement_surcharge  total_amount  \\\n",
       "0                0.00                    0.3         11.80   \n",
       "1                0.00                    0.3          4.30   \n",
       "2                0.00                    0.3         51.95   \n",
       "3                0.00                    0.3         36.35   \n",
       "4                0.00                    0.3         24.36   \n",
       "...               ...                    ...           ...   \n",
       "1369764          0.00                    0.3         38.54   \n",
       "1369765          6.12                    0.3         39.50   \n",
       "1369766          0.00                    0.3         24.05   \n",
       "1369767          0.00                    0.3         54.48   \n",
       "1369768          0.00                    0.3         29.00   \n",
       "\n",
       "         congestion_surcharge  \n",
       "0                         2.5  \n",
       "1                         0.0  \n",
       "2                         0.0  \n",
       "3                         0.0  \n",
       "4                         2.5  \n",
       "...                       ...  \n",
       "1369764                   NaN  \n",
       "1369765                   NaN  \n",
       "1369766                   NaN  \n",
       "1369767                   NaN  \n",
       "1369768                   NaN  \n",
       "\n",
       "[1369769 rows x 18 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_df = df[important_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_df['tpep_pickup_datetime']\n",
    "important_df['tpep_pickup_datetime'] = pd.to_datetime(important_df['tpep_pickup_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = int(params['year'])\n",
    "month = int(params['month'])\n",
    "\n",
    "outside_range = important_df[\n",
    "    (important_df['tpep_pickup_datetime'].dt.year != year) |\n",
    "    (important_df['tpep_pickup_datetime'].dt.month != month)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "24 rows were outside the specified year-month and have been filtered.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def check_date_range(df, year, month, date_column='tpep_pickup_datetime'):\n",
    "    \"\"\"\n",
    "    Checks if the dates in the specified column are within the given year and month.\n",
    "    \n",
    "    Args:\n",
    "    - df: The pandas DataFrame containing the data.\n",
    "    - year: The expected year for the data.\n",
    "    - month: The expected month for the data.\n",
    "    - date_column: The column name that contains the datetime data (default is 'tpep_pickup_datetime').\n",
    "    \n",
    "    Returns:\n",
    "    - filtered_df: DataFrame containing rows that match the specified year and month.\n",
    "    - outside_range: DataFrame containing rows outside the specified year and month.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert the date_column to datetime if it's not already in datetime format\n",
    "    df[date_column] = pd.to_datetime(df[date_column])\n",
    "\n",
    "    # Find rows where the year and month do not match\n",
    "    outside_range = df[\n",
    "        (df[date_column].dt.year != year) | \n",
    "        (df[date_column].dt.month != month)\n",
    "    ]\n",
    "    \n",
    "    if not outside_range.empty:\n",
    "        print(True)  # Found data outside the expected range\n",
    "        \n",
    "        # Filter to keep only the rows within the expected year and month\n",
    "        filtered_df = df[\n",
    "            (df[date_column].dt.year == year) & \n",
    "            (df[date_column].dt.month == month)\n",
    "        ]\n",
    "        print(f'{outside_range.shape[0]} rows were outside the specified year-month and have been filtered.')\n",
    "    else:\n",
    "        print(False)  # No data outside the expected range\n",
    "        filtered_df = df  # No filtering needed if all rows match\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:30:10</td>\n",
       "      <td>2021-01-01 00:36:12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>142</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>8.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.80</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:51:20</td>\n",
       "      <td>2021-01-01 00:52:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>238</td>\n",
       "      <td>151</td>\n",
       "      <td>2</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:43:30</td>\n",
       "      <td>2021-01-01 01:11:06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>132</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>42.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>51.95</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:15:48</td>\n",
       "      <td>2021-01-01 00:31:01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>36.35</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:31:49</td>\n",
       "      <td>2021-01-01 00:48:21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.94</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>68</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>16.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.36</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369764</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-31 23:03:00</td>\n",
       "      <td>2021-01-31 23:33:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>229</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>27.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>38.54</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369765</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-31 23:29:00</td>\n",
       "      <td>2021-01-31 23:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>41</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>32.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0.3</td>\n",
       "      <td>39.50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369766</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-31 23:25:00</td>\n",
       "      <td>2021-01-31 23:38:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>74</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>16.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369767</th>\n",
       "      <td>6</td>\n",
       "      <td>2021-01-31 23:01:06</td>\n",
       "      <td>2021-02-01 00:02:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>265</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>53.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>54.48</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369768</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-31 23:08:29</td>\n",
       "      <td>2021-01-31 23:31:22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>89</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>25.45</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>29.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1369769 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0               1  2021-01-01 00:30:10   2021-01-01 00:36:12              1.0   \n",
       "1               1  2021-01-01 00:51:20   2021-01-01 00:52:19              1.0   \n",
       "2               1  2021-01-01 00:43:30   2021-01-01 01:11:06              1.0   \n",
       "3               1  2021-01-01 00:15:48   2021-01-01 00:31:01              0.0   \n",
       "4               2  2021-01-01 00:31:49   2021-01-01 00:48:21              1.0   \n",
       "...           ...                  ...                   ...              ...   \n",
       "1369764         2  2021-01-31 23:03:00   2021-01-31 23:33:00              NaN   \n",
       "1369765         2  2021-01-31 23:29:00   2021-01-31 23:51:00              NaN   \n",
       "1369766         2  2021-01-31 23:25:00   2021-01-31 23:38:00              NaN   \n",
       "1369767         6  2021-01-31 23:01:06   2021-02-01 00:02:03              NaN   \n",
       "1369768         2  2021-01-31 23:08:29   2021-01-31 23:31:22              NaN   \n",
       "\n",
       "         trip_distance  RatecodeID store_and_fwd_flag  PULocationID  \\\n",
       "0                 2.10         1.0                  N           142   \n",
       "1                 0.20         1.0                  N           238   \n",
       "2                14.70         1.0                  N           132   \n",
       "3                10.60         1.0                  N           138   \n",
       "4                 4.94         1.0                  N            68   \n",
       "...                ...         ...                ...           ...   \n",
       "1369764           8.89         NaN               None           229   \n",
       "1369765           7.43         NaN               None            41   \n",
       "1369766           6.26         NaN               None            74   \n",
       "1369767          19.70         NaN               None           265   \n",
       "1369768           4.68         NaN               None            89   \n",
       "\n",
       "         DOLocationID  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
       "0                  43             2         8.00   3.00      0.5        0.00   \n",
       "1                 151             2         3.00   0.50      0.5        0.00   \n",
       "2                 165             1        42.00   0.50      0.5        8.65   \n",
       "3                 132             1        29.00   0.50      0.5        6.05   \n",
       "4                  33             1        16.50   0.50      0.5        4.06   \n",
       "...               ...           ...          ...    ...      ...         ...   \n",
       "1369764           181             0        27.78   0.00      0.5        7.46   \n",
       "1369765            70             0        32.58   0.00      0.5        0.00   \n",
       "1369766           137             0        16.85   0.00      0.5        3.90   \n",
       "1369767           188             0        53.68   0.00      0.5        0.00   \n",
       "1369768            61             0        25.45   2.75      0.5        0.00   \n",
       "\n",
       "         tolls_amount  improvement_surcharge  total_amount  \\\n",
       "0                0.00                    0.3         11.80   \n",
       "1                0.00                    0.3          4.30   \n",
       "2                0.00                    0.3         51.95   \n",
       "3                0.00                    0.3         36.35   \n",
       "4                0.00                    0.3         24.36   \n",
       "...               ...                    ...           ...   \n",
       "1369764          0.00                    0.3         38.54   \n",
       "1369765          6.12                    0.3         39.50   \n",
       "1369766          0.00                    0.3         24.05   \n",
       "1369767          0.00                    0.3         54.48   \n",
       "1369768          0.00                    0.3         29.00   \n",
       "\n",
       "         congestion_surcharge  \n",
       "0                         2.5  \n",
       "1                         0.0  \n",
       "2                         0.0  \n",
       "3                         0.0  \n",
       "4                         2.5  \n",
       "...                       ...  \n",
       "1369764                   NaN  \n",
       "1369765                   NaN  \n",
       "1369766                   NaN  \n",
       "1369767                   NaN  \n",
       "1369768                   NaN  \n",
       "\n",
       "[1369769 rows x 18 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_filtered_data(df, original_name, output_dir='../data/filtered'):\n",
    "    \"\"\"\n",
    "    Saves the filtered DataFrame to a parquet file with a prefix 'filtered_'.\n",
    "    \n",
    "    Args:\n",
    "    - df: The filtered pandas DataFrame.\n",
    "    - original_name: The original name of the data file (used for constructing the output filename).\n",
    "    - output_dir: The directory where the filtered file will be saved (default is '../data/filtered').\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Construct the new filename by adding the prefix 'filtered_' to the original filename\n",
    "    filtered_filename = f'filtered_{original_name}.parquet'\n",
    "    output_path = os.path.join(output_dir, filtered_filename)\n",
    "    \n",
    "    # Save the DataFrame to a parquet file\n",
    "    df.to_parquet(output_path)\n",
    "    print(f'Filtered data saved to {output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "24 rows were outside the specified year-month and have been filtered.\n",
      "Filtered data saved to ../data/filtered/filtered_yellow_tripdata_2021-01.parquet\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "params = {'year': 2021, 'month': 1}\n",
    "columns = ['tpep_pickup_datetime', 'PULocationID']\n",
    "\n",
    "\n",
    "filtered_df = check_date_range(important_df, params['year'], params['month'])\n",
    "# Save the filtered data\n",
    "original_filename = f'yellow_tripdata_{params[\"year\"]}-{params[\"month\"]:02d}'\n",
    "save_filtered_data(filtered_df, original_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def check_date_range(df, year, month, date_column):\n",
    "    \"\"\"\n",
    "    Checks if the dates in the specified column are within the given year and month.\n",
    "    \n",
    "    Args:\n",
    "    - df: The pandas DataFrame containing the data.\n",
    "    - year: The expected year for the data.\n",
    "    - month: The expected month for the data.\n",
    "    - date_column: The column name that contains the datetime data (default is 'pickup_datetime').\n",
    "    \n",
    "    Returns:\n",
    "    - filtered_df: DataFrame containing rows that match the specified year and month.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Rename the datetime column to 'pickup_datetime'\n",
    "    df = df.rename(columns={date_column: 'pickup_datetime'})\n",
    "\n",
    "    # Convert the renamed 'pickup_datetime' column to datetime\n",
    "    df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])\n",
    "\n",
    "    # Find rows where the year and month do not match\n",
    "    outside_range = df[\n",
    "        (df['pickup_datetime'].dt.year != year) | \n",
    "        (df['pickup_datetime'].dt.month != month)\n",
    "    ]\n",
    "    \n",
    "    if not outside_range.empty:\n",
    "        print(True)  # Found data outside the expected range\n",
    "        \n",
    "        # Filter to keep only the rows within the expected year and month\n",
    "        filtered_df = df[\n",
    "            (df['pickup_datetime'].dt.year == year) & \n",
    "            (df['pickup_datetime'].dt.month == month)\n",
    "        ]\n",
    "        print(f'{outside_range.shape[0]} rows were outside the specified year-month and have been filtered.')\n",
    "    else:\n",
    "        print('No data outside the expected range')\n",
    "        filtered_df = df  # No filtering needed if all rows match\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "\n",
    "def data_filter(df, file_type):\n",
    "    \"\"\"\n",
    "    Adjusts the datetime column, filters important columns, and drops rows with NaN values.\n",
    "    \n",
    "    Args:\n",
    "    - df: The pandas DataFrame.\n",
    "    - file_type: The type of file being processed (e.g., 'fhv_tripdata', 'yellow_tripdata').\n",
    "    \n",
    "    Returns:\n",
    "    - Filtered DataFrame with the adjusted datetime column and no NaN values in important columns.\n",
    "    \"\"\"\n",
    "    # Step 1: Rename the datetime column to 'pickup_datetime'\n",
    "    df = df.rename(columns={'pickup_datetime': 'pickup_datetime'})\n",
    "    \n",
    "    # Handle the special case for 'fhv_tripdata' where the column name is 'PUlocationID' instead of 'PULocationID'\n",
    "    if file_type == 'fhv_tripdata':\n",
    "        df = df.rename(columns={'PUlocationID': 'PULocationID'})\n",
    "    \n",
    "    # Step 2: Filter to keep only the important columns ('pickup_datetime' and 'PULocationID')\n",
    "    df = df[['pickup_datetime', 'PULocationID']]\n",
    "    \n",
    "    # Step 3: Drop rows with NaN values in 'pickup_datetime' or 'PULocationID'\n",
    "    df = df.dropna(subset=['pickup_datetime', 'PULocationID'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def save_filtered_data(df, original_name, output_dir='../data/filtered'):\n",
    "    \"\"\"\n",
    "    Saves the filtered DataFrame to a parquet file with a prefix 'filtered_'.\n",
    "    \n",
    "    Args:\n",
    "    - df: The filtered pandas DataFrame.\n",
    "    - original_name: The original name of the data file (used for constructing the output filename).\n",
    "    - output_dir: The directory where the filtered file will be saved (default is '../data/filtered').\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Construct the new filename by adding the prefix 'filtered_' to the original filename\n",
    "    filtered_filename = f'filtered_{original_name}.parquet'\n",
    "    output_path = os.path.join(output_dir, filtered_filename)\n",
    "    \n",
    "    # Save the DataFrame to a parquet file\n",
    "    df.to_parquet(output_path)\n",
    "    print(f'Filtered data saved to {output_path}')\n",
    "\n",
    "\n",
    "def process_file(filename, input_dir='../data/raw', output_dir='../data/filtered'):\n",
    "    \"\"\"\n",
    "    Processes a single parquet file by filtering data, removing NaN values, and saving the result.\n",
    "    \n",
    "    Args:\n",
    "    - filename: The name of the file to process.\n",
    "    - input_dir: The directory where the parquet file is located.\n",
    "    - output_dir: The directory where the filtered parquet file will be saved.\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Construct the filtered file name and path\n",
    "        filtered_filename = f'filtered_{filename}'\n",
    "        filtered_file_path = os.path.join(output_dir, filtered_filename)\n",
    "\n",
    "        # Check if the filtered file already exists\n",
    "        if Path(filtered_file_path).exists():\n",
    "            print(f'{filtered_filename} already exists. Skipping processing.')\n",
    "            return  # Skip this file since it's already processed\n",
    "        \n",
    "        # Known patterns and corresponding original date columns\n",
    "        file_patterns = {\n",
    "            'yellow_tripdata': 'tpep_pickup_datetime',\n",
    "            'green_tripdata': 'lpep_pickup_datetime',\n",
    "            'fhv_tripdata': 'pickup_datetime',   # Corrected for fhv files\n",
    "            'fhvhv_tripdata': 'pickup_datetime'\n",
    "        }\n",
    "        \n",
    "        for pattern, original_date_column in file_patterns.items():\n",
    "            if filename.startswith(pattern):\n",
    "                try:\n",
    "                    # Extract year and month from the filename\n",
    "                    parts = filename.split('_')\n",
    "                    file_year, file_month = parts[-1].split('.')[0].split('-')\n",
    "                    file_year = int(file_year)\n",
    "                    file_month = int(file_month)\n",
    "\n",
    "                    # Load the parquet file\n",
    "                    file_path = os.path.join(input_dir, filename)\n",
    "                    df = pd.read_parquet(file_path)\n",
    "\n",
    "                    # Check if the dates are within the expected range\n",
    "                    df = check_date_range(df, file_year, file_month, original_date_column)\n",
    "                    \n",
    "                    # Apply data filtering (adjust datetime, filter columns, drop NaN)\n",
    "                    df = data_filter(df, pattern)  # Pass the file pattern to handle column name differences\n",
    "                    \n",
    "                    # Save the filtered DataFrame\n",
    "                    save_filtered_data(df, filename.replace('.parquet', ''), output_dir)\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "                break\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {filename} not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error processing {filename}: {e}\")\n",
    "\n",
    "\n",
    "def process_all_parquet_files_in_directory(input_dir='../data/raw', output_dir='../data/filtered'):\n",
    "    \"\"\"\n",
    "    Processes all parquet files in the input directory that follow the known patterns.\n",
    "    \n",
    "    Args:\n",
    "    - input_dir: The directory where the raw parquet files are located.\n",
    "    - output_dir: The directory where the filtered parquet files will be saved.\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith('.parquet'):\n",
    "            try:\n",
    "                process_file(filename, input_dir, output_dir)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {filename}: {e}\")\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the parquet processing from ../data/raw to ../data/filtered...\n",
      "No data outside the expected range\n",
      "Filtered data saved to ../data/filtered/filtered_fhvhv_tripdata_2022-03.parquet\n",
      "filtered_yellow_tripdata_2023-07.parquet already exists. Skipping processing.\n",
      "No data outside the expected range\n",
      "Filtered data saved to ../data/filtered/filtered_fhv_tripdata_2021-12.parquet\n",
      "filtered_yellow_tripdata_2021-08.parquet already exists. Skipping processing.\n",
      "True\n",
      "2 rows were outside the specified year-month and have been filtered.\n",
      "Filtered data saved to ../data/filtered/filtered_green_tripdata_2021-06.parquet\n",
      "No data outside the expected range\n",
      "Filtered data saved to ../data/filtered/filtered_fhvhv_tripdata_2021-07.parquet\n",
      "filtered_yellow_tripdata_2022-04.parquet already exists. Skipping processing.\n",
      "No data outside the expected range\n",
      "Filtered data saved to ../data/filtered/filtered_fhvhv_tripdata_2021-12.parquet\n",
      "filtered_yellow_tripdata_2022-05.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2023-10.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2021-03.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2022-12.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2021-02.parquet already exists. Skipping processing.\n",
      "No data outside the expected range\n",
      "Filtered data saved to ../data/filtered/filtered_fhv_tripdata_2022-02.parquet\n",
      "No data outside the expected range\n",
      "Filtered data saved to ../data/filtered/filtered_fhvhv_tripdata_2021-08.parquet\n",
      "filtered_yellow_tripdata_2023-05.parquet already exists. Skipping processing.\n",
      "No data outside the expected range\n",
      "Filtered data saved to ../data/filtered/filtered_fhv_tripdata_2022-03.parquet\n",
      "No data outside the expected range\n",
      "Filtered data saved to ../data/filtered/filtered_fhvhv_tripdata_2021-10.parquet\n",
      "No data outside the expected range\n",
      "Filtered data saved to ../data/filtered/filtered_fhv_tripdata_2022-05.parquet\n",
      "filtered_yellow_tripdata_2022-02.parquet already exists. Skipping processing.\n",
      "No data outside the expected range\n",
      "Filtered data saved to ../data/filtered/filtered_fhvhv_tripdata_2022-01.parquet\n",
      "filtered_green_tripdata_2021-01.parquet already exists. Skipping processing.\n",
      "True\n",
      "7 rows were outside the specified year-month and have been filtered.\n",
      "Filtered data saved to ../data/filtered/filtered_green_tripdata_2021-10.parquet\n",
      "filtered_yellow_tripdata_2023-12.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2021-05.parquet already exists. Skipping processing.\n",
      "True\n",
      "7 rows were outside the specified year-month and have been filtered.\n",
      "Filtered data saved to ../data/filtered/filtered_green_tripdata_2021-09.parquet\n",
      "filtered_fhvhv_tripdata_2021-02.parquet already exists. Skipping processing.\n",
      "No data outside the expected range\n",
      "Filtered data saved to ../data/filtered/filtered_fhv_tripdata_2021-05.parquet\n",
      "filtered_yellow_tripdata_2023-06.parquet already exists. Skipping processing.\n",
      "filtered_fhv_tripdata_2021-01.parquet already exists. Skipping processing.\n",
      "filtered_fhvhv_tripdata_2021-01.parquet already exists. Skipping processing.\n",
      "True\n",
      "6 rows were outside the specified year-month and have been filtered.\n",
      "Filtered data saved to ../data/filtered/filtered_green_tripdata_2021-12.parquet\n",
      "No data outside the expected range\n",
      "Filtered data saved to ../data/filtered/filtered_fhv_tripdata_2021-08.parquet\n",
      "filtered_yellow_tripdata_2023-11.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2021-01.parquet already exists. Skipping processing.\n",
      "No data outside the expected range\n",
      "Filtered data saved to ../data/filtered/filtered_fhv_tripdata_2022-07.parquet\n",
      "filtered_yellow_tripdata_2021-11.parquet already exists. Skipping processing.\n",
      "True\n",
      "4 rows were outside the specified year-month and have been filtered.\n",
      "Filtered data saved to ../data/filtered/filtered_green_tripdata_2022-07.parquet\n",
      "True\n",
      "9 rows were outside the specified year-month and have been filtered.\n",
      "Filtered data saved to ../data/filtered/filtered_green_tripdata_2022-06.parquet\n",
      "No data outside the expected range\n",
      "Filtered data saved to ../data/filtered/filtered_fhv_tripdata_2021-06.parquet\n",
      "filtered_yellow_tripdata_2022-09.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2021-04.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2022-08.parquet already exists. Skipping processing.\n",
      "True\n",
      "7 rows were outside the specified year-month and have been filtered.\n",
      "Filtered data saved to ../data/filtered/filtered_green_tripdata_2021-05.parquet\n",
      "filtered_yellow_tripdata_2023-03.parquet already exists. Skipping processing.\n",
      "No data outside the expected range\n",
      "Filtered data saved to ../data/filtered/filtered_fhvhv_tripdata_2022-06.parquet\n",
      "filtered_yellow_tripdata_2023-01.parquet already exists. Skipping processing.\n",
      "No data outside the expected range\n",
      "Filtered data saved to ../data/filtered/filtered_fhv_tripdata_2021-07.parquet\n",
      "No data outside the expected range\n",
      "Filtered data saved to ../data/filtered/filtered_fhvhv_tripdata_2022-04.parquet\n",
      "True\n",
      "24 rows were outside the specified year-month and have been filtered.\n",
      "Filtered data saved to ../data/filtered/filtered_green_tripdata_2022-03.parquet\n",
      "True\n",
      "13 rows were outside the specified year-month and have been filtered.\n",
      "Filtered data saved to ../data/filtered/filtered_green_tripdata_2021-04.parquet\n",
      "True\n",
      "17 rows were outside the specified year-month and have been filtered.\n",
      "Filtered data saved to ../data/filtered/filtered_green_tripdata_2022-05.parquet\n",
      "filtered_yellow_tripdata_2022-03.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2021-12.parquet already exists. Skipping processing.\n",
      "No data outside the expected range\n",
      "Filtered data saved to ../data/filtered/filtered_fhv_tripdata_2022-04.parquet\n",
      "filtered_yellow_tripdata_2021-06.parquet already exists. Skipping processing.\n",
      "filtered_fhv_tripdata_2021-02.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2021-09.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2022-01.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2023-04.parquet already exists. Skipping processing.\n",
      "filtered_green_tripdata_2021-02.parquet already exists. Skipping processing.\n",
      "No data outside the expected range\n",
      "Filtered data saved to ../data/filtered/filtered_fhvhv_tripdata_2021-06.parquet\n",
      "No data outside the expected range\n",
      "Filtered data saved to ../data/filtered/filtered_fhvhv_tripdata_2021-11.parquet\n",
      "No data outside the expected range\n",
      "Filtered data saved to ../data/filtered/filtered_fhvhv_tripdata_2022-05.parquet\n",
      "True\n",
      "10 rows were outside the specified year-month and have been filtered.\n",
      "Filtered data saved to ../data/filtered/filtered_green_tripdata_2021-08.parquet\n",
      "No data outside the expected range\n",
      "Filtered data saved to ../data/filtered/filtered_fhv_tripdata_2021-04.parquet\n",
      "filtered_yellow_tripdata_2023-08.parquet already exists. Skipping processing.\n",
      "filtered_fhvhv_tripdata_2021-03.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2023-02.parquet already exists. Skipping processing.\n",
      "True\n",
      "35 rows were outside the specified year-month and have been filtered.\n",
      "Filtered data saved to ../data/filtered/filtered_green_tripdata_2022-04.parquet\n",
      "filtered_fhv_tripdata_2021-03.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2022-10.parquet already exists. Skipping processing.\n",
      "True\n",
      "7 rows were outside the specified year-month and have been filtered.\n",
      "Filtered data saved to ../data/filtered/filtered_green_tripdata_2021-11.parquet\n",
      "filtered_yellow_tripdata_2023-09.parquet already exists. Skipping processing.\n",
      "No data outside the expected range\n",
      "Filtered data saved to ../data/filtered/filtered_fhv_tripdata_2021-10.parquet\n",
      "filtered_yellow_tripdata_2021-07.parquet already exists. Skipping processing.\n",
      "filtered_green_tripdata_2021-03.parquet already exists. Skipping processing.\n",
      "No data outside the expected range\n",
      "Filtered data saved to ../data/filtered/filtered_fhvhv_tripdata_2021-04.parquet\n",
      "No data outside the expected range\n",
      "Filtered data saved to ../data/filtered/filtered_fhv_tripdata_2021-09.parquet\n",
      "filtered_yellow_tripdata_2022-06.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2021-10.parquet already exists. Skipping processing.\n",
      "No data outside the expected range\n",
      "Filtered data saved to ../data/filtered/filtered_fhvhv_tripdata_2021-09.parquet\n",
      "No data outside the expected range\n",
      "Filtered data saved to ../data/filtered/filtered_fhvhv_tripdata_2022-02.parquet\n",
      "True\n",
      "4 rows were outside the specified year-month and have been filtered.\n",
      "Filtered data saved to ../data/filtered/filtered_green_tripdata_2022-01.parquet\n",
      "No data outside the expected range\n",
      "Filtered data saved to ../data/filtered/filtered_fhv_tripdata_2022-01.parquet\n",
      "No data outside the expected range\n",
      "Filtered data saved to ../data/filtered/filtered_fhv_tripdata_2022-06.parquet\n",
      "No data outside the expected range\n",
      "Filtered data saved to ../data/filtered/filtered_fhvhv_tripdata_2021-05.parquet\n",
      "filtered_yellow_tripdata_2022-07.parquet already exists. Skipping processing.\n",
      "filtered_yellow_tripdata_2022-11.parquet already exists. Skipping processing.\n",
      "True\n",
      "23 rows were outside the specified year-month and have been filtered.\n",
      "Filtered data saved to ../data/filtered/filtered_green_tripdata_2022-02.parquet\n",
      "No data outside the expected range\n",
      "Filtered data saved to ../data/filtered/filtered_fhv_tripdata_2021-11.parquet\n",
      "True\n",
      "18 rows were outside the specified year-month and have been filtered.\n",
      "Filtered data saved to ../data/filtered/filtered_green_tripdata_2021-07.parquet\n",
      "Processing complete. Check ../data/filtered for the filtered files.\n"
     ]
    }
   ],
   "source": [
    "# Test script for processing parquet files\n",
    "\n",
    "# Directory setup for test (change if needed)\n",
    "input_directory = '../data/raw'\n",
    "output_directory = '../data/filtered'\n",
    "\n",
    "# Assuming you have some .parquet files in the input directory\n",
    "# Example: 'yellow_tripdata_2021-01.parquet', 'green_tripdata_2021-01.parquet'\n",
    "\n",
    "def test_parquet_processing():\n",
    "    print(f\"Starting the parquet processing from {input_directory} to {output_directory}...\")\n",
    "\n",
    "    # Call the function to process all files in the directory\n",
    "    process_all_parquet_files_in_directory(input_dir=input_directory, output_dir=output_directory)\n",
    "\n",
    "    print(f\"Processing complete. Check {output_directory} for the filtered files.\")\n",
    "\n",
    "# Run the test\n",
    "if __name__ == \"__main__\":\n",
    "    test_parquet_processing()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "src-k1b3gFX9-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
